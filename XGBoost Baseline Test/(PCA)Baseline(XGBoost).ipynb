{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93cdbfb3-3aee-48cd-9b59-2f9a25604097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ ËÆÄÂèñ: Y:\\Âõ†Â≠êÂõûÊ∏¨_Ê±üÂª∫ÂΩ∞\\Âõ†Â≠êÂ∫´.pkl\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import math\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from flash_attn import flash_attn_func\n",
    "from xgboost import XGBRegressor, DMatrix\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "\n",
    "from kneed import KneeLocator\n",
    "from collections import defaultdict\n",
    "\n",
    "from gpu_pca import IncrementalPCAonGPU\n",
    "\n",
    "# Ëá™Ë®ÇÊ®°ÁµÑ\n",
    "from library import StockUniverse, FactorLibrary, MarketInfo, FileLoader, FactorLibrary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0af3f8-287f-467a-82a1-6b60ae043b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d0967d3-6ce8-48b6-847f-e42298444def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ ËÆÄÂèñ: Y:\\Âõ†Â≠êÂõûÊ∏¨_Ê±üÂª∫ÂΩ∞\\Âõ†Â≠êÂ∫´TWSE.pkl\n"
     ]
    }
   ],
   "source": [
    "stock_universe = 'TWSE'\n",
    "flib = FactorLibrary2(path=f'Y:\\Âõ†Â≠êÂõûÊ∏¨_Ê±üÂª∫ÂΩ∞\\Âõ†Â≠êÂ∫´{stock_universe}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20ababa8-c08c-4ddf-ae5e-f529dd9df98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AllDayFactorDataset(Dataset):\n",
    "    def __init__(self, stock_universe='TWSE'):\n",
    "        self.multi_df = FileLoader.load(f'Y:\\Âõ†Â≠êÂõûÊ∏¨_Ê±üÂª∫ÂΩ∞\\Âõ†Â≠êÂ∫´{stock_universe}.pkl')\n",
    "        self.adj_close_df = pd.read_feather(r'Y:\\Âõ†Â≠êÂõûÊ∏¨_Ê±üÂª∫ÂΩ∞\\Ë£ú‰∏äÁº∫ÂÄºÊó•È†ªÊî∂Áõ§ÂÉπ.ftr')\n",
    "        self.stock_list = self.get_stock_list(stock_universe)\n",
    "        \n",
    "        self.TPEX_df = MarketInfo.TPEX_norm()\n",
    "        self.RoR_df = (self.adj_close_df.shift(-5) - self.adj_close_df.shift(-1)) / self.adj_close_df.shift(-1)\n",
    "        self.RoR_df.dropna(axis=0, inplace=True)\n",
    "\n",
    "\n",
    "        new_ticker_list = self.multi_df.columns.get_level_values('ticker')\n",
    "        new_ticker_list = new_ticker_list[~new_ticker_list.duplicated()]\n",
    "\n",
    "        self.stock_list = new_ticker_list\n",
    "        self.RoR_df = self.RoR_df[self.stock_list]\n",
    "        self.adj_close_df = self.adj_close_df[self.stock_list]\n",
    "        # ÈÄôË£°ÊâÄÊúâÂÄºÈÉΩÂåÖÂê´Áï∂Â§©Ë≥áË®äÊâÄ‰ª•Ë¶ÅÂêëÂæåÁßª\n",
    "        self.restrict_range()\n",
    "        self.check_validility()\n",
    "\n",
    "    def check_validility(self):\n",
    "        ticker_list1 = self.stock_list\n",
    "        ticker_list2 = self.RoR_df.columns\n",
    "        ticker_list3 = self.multi_df.columns.get_level_values('ticker')\n",
    "        ticker_list3 = ticker_list3[~ticker_list3.duplicated()]\n",
    "        assert len(ticker_list1)==len(ticker_list2)==len(ticker_list3)\n",
    "        \n",
    "        BOOL = True\n",
    "        for i in range(len(ticker_list1)):\n",
    "            if not (ticker_list1[i]==ticker_list2[i]==ticker_list3[i]):\n",
    "                BOOL = False\n",
    "        assert BOOL==True\n",
    "        \n",
    "\n",
    "        factor_list = self.multi_df.columns.get_level_values('factor')\n",
    "        factor_list = factor_list[~factor_list.duplicated()]\n",
    "        BOOL = True\n",
    "        for factor_name in factor_list:\n",
    "            ticker_list4 = self.multi_df.loc[ : , factor_name].columns\n",
    "            for i in range(len(ticker_list1)):\n",
    "                if ticker_list1[i]!=ticker_list4[i]:\n",
    "                    BOOL = False\n",
    "        assert BOOL==True\n",
    "        \n",
    "    \n",
    "\n",
    "    def restrict_range(self, global_start='2020-04-01', global_end='2025-04-09'):\n",
    "        self.multi_df     = self.multi_df.loc[global_start : global_end]\n",
    "        self.adj_close_df = self.adj_close_df.loc[global_start : global_end]\n",
    "        self.TPEX_df      = self.TPEX_df.loc[global_start : global_end]\n",
    "        self.RoR_df       = self.RoR_df.loc[global_start : global_end]\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_stock_list(self, stock_univserse):\n",
    "        if stock_univserse=='TWSE':\n",
    "            ticker1 = StockUniverse.TWSE() \n",
    "        elif stock_univserse=='OTC':\n",
    "            ticker1 = StockUniverse.OTC()\n",
    "        elif stock_univserse=='all':\n",
    "            ticker1 = StockUniverse.all()\n",
    "            \n",
    "        \n",
    "        ticker2 = self.multi_df.columns.get_level_values('ticker')\n",
    "        ticker3 = self.adj_close_df.columns\n",
    "        return list(set(ticker1)&set(ticker2)&set(ticker3))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9610f865-2866-4d60-81ae-4e0a75186b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Âø´Âèñ‰ΩøÁî®: Y:\\Âõ†Â≠êÂõûÊ∏¨_Ê±üÂª∫ÂΩ∞\\Âõ†Â≠êÂ∫´TWSE.pkl\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "factor_dataset = AllDayFactorDataset(stock_universe='TWSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91eb103e-a876-4351-896e-9c6ccb191acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "RoR_df = factor_dataset.RoR_df\n",
    "z_return_df = (RoR_df - RoR_df.mean(axis=1).values[:, None]) / RoR_df.std(axis=1).values[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb82f34a-0534-4f27-974d-19863731d189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>factor</th>\n",
       "      <th colspan=\"10\" halign=\"left\">factor_0</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">factor_185</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th>1101</th>\n",
       "      <th>1102</th>\n",
       "      <th>1103</th>\n",
       "      <th>1104</th>\n",
       "      <th>1108</th>\n",
       "      <th>1109</th>\n",
       "      <th>1110</th>\n",
       "      <th>1201</th>\n",
       "      <th>1203</th>\n",
       "      <th>1210</th>\n",
       "      <th>...</th>\n",
       "      <th>9939</th>\n",
       "      <th>9940</th>\n",
       "      <th>9941</th>\n",
       "      <th>9942</th>\n",
       "      <th>9943</th>\n",
       "      <th>9944</th>\n",
       "      <th>9945</th>\n",
       "      <th>9946</th>\n",
       "      <th>9955</th>\n",
       "      <th>9958</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-04-01</th>\n",
       "      <td>-0.673939</td>\n",
       "      <td>-0.455914</td>\n",
       "      <td>-0.600366</td>\n",
       "      <td>-0.193277</td>\n",
       "      <td>1.754857</td>\n",
       "      <td>-0.967506</td>\n",
       "      <td>-1.611826</td>\n",
       "      <td>1.346149</td>\n",
       "      <td>-0.139294</td>\n",
       "      <td>0.163777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066802</td>\n",
       "      <td>0.072487</td>\n",
       "      <td>0.058731</td>\n",
       "      <td>0.070173</td>\n",
       "      <td>0.068826</td>\n",
       "      <td>0.072342</td>\n",
       "      <td>0.041585</td>\n",
       "      <td>0.107296</td>\n",
       "      <td>0.074130</td>\n",
       "      <td>0.078821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-06</th>\n",
       "      <td>-0.327203</td>\n",
       "      <td>-0.146773</td>\n",
       "      <td>-0.556454</td>\n",
       "      <td>-0.166725</td>\n",
       "      <td>1.027622</td>\n",
       "      <td>-0.758691</td>\n",
       "      <td>-2.130461</td>\n",
       "      <td>-0.347443</td>\n",
       "      <td>-1.021574</td>\n",
       "      <td>-0.870032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082190</td>\n",
       "      <td>0.082626</td>\n",
       "      <td>0.078126</td>\n",
       "      <td>0.092643</td>\n",
       "      <td>0.096279</td>\n",
       "      <td>0.101995</td>\n",
       "      <td>0.070161</td>\n",
       "      <td>0.119151</td>\n",
       "      <td>0.100967</td>\n",
       "      <td>0.086217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-07</th>\n",
       "      <td>0.098016</td>\n",
       "      <td>1.224380</td>\n",
       "      <td>0.101407</td>\n",
       "      <td>0.234013</td>\n",
       "      <td>0.153450</td>\n",
       "      <td>-0.239635</td>\n",
       "      <td>-1.987577</td>\n",
       "      <td>-0.916866</td>\n",
       "      <td>-0.984516</td>\n",
       "      <td>-0.930563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068940</td>\n",
       "      <td>0.073008</td>\n",
       "      <td>0.074640</td>\n",
       "      <td>0.075921</td>\n",
       "      <td>0.077645</td>\n",
       "      <td>0.111064</td>\n",
       "      <td>0.090337</td>\n",
       "      <td>0.051750</td>\n",
       "      <td>0.089592</td>\n",
       "      <td>0.078324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-08</th>\n",
       "      <td>-0.319991</td>\n",
       "      <td>0.674528</td>\n",
       "      <td>0.049169</td>\n",
       "      <td>0.289316</td>\n",
       "      <td>-0.621626</td>\n",
       "      <td>-0.291409</td>\n",
       "      <td>-1.360423</td>\n",
       "      <td>-0.868599</td>\n",
       "      <td>-0.781669</td>\n",
       "      <td>-0.766940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055604</td>\n",
       "      <td>0.033972</td>\n",
       "      <td>0.036535</td>\n",
       "      <td>0.031070</td>\n",
       "      <td>0.035563</td>\n",
       "      <td>0.098852</td>\n",
       "      <td>0.055969</td>\n",
       "      <td>-0.003307</td>\n",
       "      <td>0.017020</td>\n",
       "      <td>0.083563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-09</th>\n",
       "      <td>-0.232543</td>\n",
       "      <td>0.327937</td>\n",
       "      <td>0.066867</td>\n",
       "      <td>0.110226</td>\n",
       "      <td>-0.713421</td>\n",
       "      <td>-0.238935</td>\n",
       "      <td>-0.264998</td>\n",
       "      <td>-0.536980</td>\n",
       "      <td>-0.391901</td>\n",
       "      <td>-0.507913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049386</td>\n",
       "      <td>0.022256</td>\n",
       "      <td>0.040502</td>\n",
       "      <td>0.031352</td>\n",
       "      <td>0.046665</td>\n",
       "      <td>0.097971</td>\n",
       "      <td>0.031984</td>\n",
       "      <td>0.103135</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.043055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01</th>\n",
       "      <td>0.340768</td>\n",
       "      <td>0.900310</td>\n",
       "      <td>0.464735</td>\n",
       "      <td>0.591395</td>\n",
       "      <td>0.006090</td>\n",
       "      <td>0.103580</td>\n",
       "      <td>1.969913</td>\n",
       "      <td>0.432038</td>\n",
       "      <td>0.489601</td>\n",
       "      <td>0.704419</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.143642</td>\n",
       "      <td>-0.416881</td>\n",
       "      <td>-0.168819</td>\n",
       "      <td>0.081369</td>\n",
       "      <td>0.144244</td>\n",
       "      <td>1.824791</td>\n",
       "      <td>-0.507640</td>\n",
       "      <td>-1.891102</td>\n",
       "      <td>1.824791</td>\n",
       "      <td>0.835318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-02</th>\n",
       "      <td>1.004445</td>\n",
       "      <td>0.171334</td>\n",
       "      <td>-0.185994</td>\n",
       "      <td>0.407952</td>\n",
       "      <td>-0.374743</td>\n",
       "      <td>-0.487857</td>\n",
       "      <td>1.728988</td>\n",
       "      <td>1.728988</td>\n",
       "      <td>1.096996</td>\n",
       "      <td>1.728988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.992188</td>\n",
       "      <td>0.137274</td>\n",
       "      <td>1.358135</td>\n",
       "      <td>0.246138</td>\n",
       "      <td>0.452394</td>\n",
       "      <td>1.848424</td>\n",
       "      <td>-0.107221</td>\n",
       "      <td>-1.861662</td>\n",
       "      <td>1.848424</td>\n",
       "      <td>1.022157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-07</th>\n",
       "      <td>1.361418</td>\n",
       "      <td>1.361418</td>\n",
       "      <td>1.182799</td>\n",
       "      <td>1.361418</td>\n",
       "      <td>1.356861</td>\n",
       "      <td>1.361418</td>\n",
       "      <td>1.361418</td>\n",
       "      <td>1.361418</td>\n",
       "      <td>1.361418</td>\n",
       "      <td>1.361418</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008507</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.073191</td>\n",
       "      <td>0.038328</td>\n",
       "      <td>0.005722</td>\n",
       "      <td>0.076073</td>\n",
       "      <td>0.036290</td>\n",
       "      <td>0.023162</td>\n",
       "      <td>0.076073</td>\n",
       "      <td>0.074417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-08</th>\n",
       "      <td>1.427229</td>\n",
       "      <td>1.427229</td>\n",
       "      <td>1.427229</td>\n",
       "      <td>1.427229</td>\n",
       "      <td>1.427229</td>\n",
       "      <td>1.427229</td>\n",
       "      <td>1.427229</td>\n",
       "      <td>1.427229</td>\n",
       "      <td>1.427229</td>\n",
       "      <td>1.427229</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027256</td>\n",
       "      <td>-0.034378</td>\n",
       "      <td>-0.011736</td>\n",
       "      <td>-0.036078</td>\n",
       "      <td>-0.000374</td>\n",
       "      <td>0.047075</td>\n",
       "      <td>0.018541</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.104005</td>\n",
       "      <td>0.104005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-09</th>\n",
       "      <td>1.450276</td>\n",
       "      <td>1.450276</td>\n",
       "      <td>1.450276</td>\n",
       "      <td>1.450276</td>\n",
       "      <td>1.450276</td>\n",
       "      <td>1.450276</td>\n",
       "      <td>1.167629</td>\n",
       "      <td>1.378374</td>\n",
       "      <td>1.450276</td>\n",
       "      <td>1.450276</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067628</td>\n",
       "      <td>0.004631</td>\n",
       "      <td>-0.126421</td>\n",
       "      <td>-0.091972</td>\n",
       "      <td>-0.039853</td>\n",
       "      <td>-0.126421</td>\n",
       "      <td>-0.023461</td>\n",
       "      <td>-0.007847</td>\n",
       "      <td>0.156484</td>\n",
       "      <td>0.178677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1220 rows √ó 164982 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "factor      factor_0                                                    \\\n",
       "ticker          1101      1102      1103      1104      1108      1109   \n",
       "Date                                                                     \n",
       "2020-04-01 -0.673939 -0.455914 -0.600366 -0.193277  1.754857 -0.967506   \n",
       "2020-04-06 -0.327203 -0.146773 -0.556454 -0.166725  1.027622 -0.758691   \n",
       "2020-04-07  0.098016  1.224380  0.101407  0.234013  0.153450 -0.239635   \n",
       "2020-04-08 -0.319991  0.674528  0.049169  0.289316 -0.621626 -0.291409   \n",
       "2020-04-09 -0.232543  0.327937  0.066867  0.110226 -0.713421 -0.238935   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2025-04-01  0.340768  0.900310  0.464735  0.591395  0.006090  0.103580   \n",
       "2025-04-02  1.004445  0.171334 -0.185994  0.407952 -0.374743 -0.487857   \n",
       "2025-04-07  1.361418  1.361418  1.182799  1.361418  1.356861  1.361418   \n",
       "2025-04-08  1.427229  1.427229  1.427229  1.427229  1.427229  1.427229   \n",
       "2025-04-09  1.450276  1.450276  1.450276  1.450276  1.450276  1.450276   \n",
       "\n",
       "factor                                              ... factor_185            \\\n",
       "ticker          1110      1201      1203      1210  ...       9939      9940   \n",
       "Date                                                ...                        \n",
       "2020-04-01 -1.611826  1.346149 -0.139294  0.163777  ...   0.066802  0.072487   \n",
       "2020-04-06 -2.130461 -0.347443 -1.021574 -0.870032  ...   0.082190  0.082626   \n",
       "2020-04-07 -1.987577 -0.916866 -0.984516 -0.930563  ...   0.068940  0.073008   \n",
       "2020-04-08 -1.360423 -0.868599 -0.781669 -0.766940  ...   0.055604  0.033972   \n",
       "2020-04-09 -0.264998 -0.536980 -0.391901 -0.507913  ...   0.049386  0.022256   \n",
       "...              ...       ...       ...       ...  ...        ...       ...   \n",
       "2025-04-01  1.969913  0.432038  0.489601  0.704419  ...  -1.143642 -0.416881   \n",
       "2025-04-02  1.728988  1.728988  1.096996  1.728988  ...  -0.992188  0.137274   \n",
       "2025-04-07  1.361418  1.361418  1.361418  1.361418  ...  -0.008507  0.000583   \n",
       "2025-04-08  1.427229  1.427229  1.427229  1.427229  ...  -0.027256 -0.034378   \n",
       "2025-04-09  1.167629  1.378374  1.450276  1.450276  ...  -0.067628  0.004631   \n",
       "\n",
       "factor                                                                  \\\n",
       "ticker          9941      9942      9943      9944      9945      9946   \n",
       "Date                                                                     \n",
       "2020-04-01  0.058731  0.070173  0.068826  0.072342  0.041585  0.107296   \n",
       "2020-04-06  0.078126  0.092643  0.096279  0.101995  0.070161  0.119151   \n",
       "2020-04-07  0.074640  0.075921  0.077645  0.111064  0.090337  0.051750   \n",
       "2020-04-08  0.036535  0.031070  0.035563  0.098852  0.055969 -0.003307   \n",
       "2020-04-09  0.040502  0.031352  0.046665  0.097971  0.031984  0.103135   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2025-04-01 -0.168819  0.081369  0.144244  1.824791 -0.507640 -1.891102   \n",
       "2025-04-02  1.358135  0.246138  0.452394  1.848424 -0.107221 -1.861662   \n",
       "2025-04-07  0.073191  0.038328  0.005722  0.076073  0.036290  0.023162   \n",
       "2025-04-08 -0.011736 -0.036078 -0.000374  0.047075  0.018541  0.000232   \n",
       "2025-04-09 -0.126421 -0.091972 -0.039853 -0.126421 -0.023461 -0.007847   \n",
       "\n",
       "factor                          \n",
       "ticker          9955      9958  \n",
       "Date                            \n",
       "2020-04-01  0.074130  0.078821  \n",
       "2020-04-06  0.100967  0.086217  \n",
       "2020-04-07  0.089592  0.078324  \n",
       "2020-04-08  0.017020  0.083563  \n",
       "2020-04-09  0.003805  0.043055  \n",
       "...              ...       ...  \n",
       "2025-04-01  1.824791  0.835318  \n",
       "2025-04-02  1.848424  1.022157  \n",
       "2025-04-07  0.076073  0.074417  \n",
       "2025-04-08  0.104005  0.104005  \n",
       "2025-04-09  0.156484  0.178677  \n",
       "\n",
       "[1220 rows x 164982 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_dataset.multi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ae6aea4-f020-4985-b550-39781506322a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>symbol_id</th>\n",
       "      <th>1101</th>\n",
       "      <th>1102</th>\n",
       "      <th>1103</th>\n",
       "      <th>1104</th>\n",
       "      <th>1108</th>\n",
       "      <th>1109</th>\n",
       "      <th>1110</th>\n",
       "      <th>1201</th>\n",
       "      <th>1203</th>\n",
       "      <th>1210</th>\n",
       "      <th>...</th>\n",
       "      <th>9939</th>\n",
       "      <th>9940</th>\n",
       "      <th>9941</th>\n",
       "      <th>9942</th>\n",
       "      <th>9943</th>\n",
       "      <th>9944</th>\n",
       "      <th>9945</th>\n",
       "      <th>9946</th>\n",
       "      <th>9955</th>\n",
       "      <th>9958</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trade_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-04-01</th>\n",
       "      <td>-0.165141</td>\n",
       "      <td>0.396585</td>\n",
       "      <td>0.078443</td>\n",
       "      <td>0.089599</td>\n",
       "      <td>-0.619321</td>\n",
       "      <td>-0.148782</td>\n",
       "      <td>-0.933043</td>\n",
       "      <td>-0.686305</td>\n",
       "      <td>-0.901289</td>\n",
       "      <td>-0.731514</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.416946</td>\n",
       "      <td>0.616390</td>\n",
       "      <td>0.865555</td>\n",
       "      <td>-0.155905</td>\n",
       "      <td>-0.268315</td>\n",
       "      <td>-1.961625</td>\n",
       "      <td>-1.344977</td>\n",
       "      <td>0.984428</td>\n",
       "      <td>0.483491</td>\n",
       "      <td>-0.488042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-06</th>\n",
       "      <td>-0.277162</td>\n",
       "      <td>0.299730</td>\n",
       "      <td>0.009240</td>\n",
       "      <td>0.353117</td>\n",
       "      <td>-0.010091</td>\n",
       "      <td>0.044924</td>\n",
       "      <td>0.815303</td>\n",
       "      <td>-0.652765</td>\n",
       "      <td>-0.360477</td>\n",
       "      <td>-0.378793</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.460243</td>\n",
       "      <td>0.036481</td>\n",
       "      <td>0.434861</td>\n",
       "      <td>-0.045912</td>\n",
       "      <td>0.179594</td>\n",
       "      <td>-0.824940</td>\n",
       "      <td>-0.726843</td>\n",
       "      <td>3.296798</td>\n",
       "      <td>0.899926</td>\n",
       "      <td>-0.943563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-07</th>\n",
       "      <td>-0.386795</td>\n",
       "      <td>-0.370135</td>\n",
       "      <td>-0.196156</td>\n",
       "      <td>0.088294</td>\n",
       "      <td>0.371439</td>\n",
       "      <td>-0.151109</td>\n",
       "      <td>0.292804</td>\n",
       "      <td>-0.508770</td>\n",
       "      <td>-0.557872</td>\n",
       "      <td>0.005393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.385102</td>\n",
       "      <td>-0.630818</td>\n",
       "      <td>0.216666</td>\n",
       "      <td>-0.017604</td>\n",
       "      <td>-0.245133</td>\n",
       "      <td>-1.081967</td>\n",
       "      <td>-0.760730</td>\n",
       "      <td>1.611201</td>\n",
       "      <td>1.893717</td>\n",
       "      <td>-1.222098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-08</th>\n",
       "      <td>-0.337903</td>\n",
       "      <td>-0.311649</td>\n",
       "      <td>0.183218</td>\n",
       "      <td>-0.299780</td>\n",
       "      <td>0.037332</td>\n",
       "      <td>-0.164683</td>\n",
       "      <td>-0.697732</td>\n",
       "      <td>-0.454069</td>\n",
       "      <td>-0.728089</td>\n",
       "      <td>0.217207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.521642</td>\n",
       "      <td>-0.991485</td>\n",
       "      <td>0.152767</td>\n",
       "      <td>0.299659</td>\n",
       "      <td>0.876070</td>\n",
       "      <td>-1.256489</td>\n",
       "      <td>-0.638734</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>1.738175</td>\n",
       "      <td>-0.584666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-09</th>\n",
       "      <td>-0.309666</td>\n",
       "      <td>-0.202460</td>\n",
       "      <td>-0.103384</td>\n",
       "      <td>-0.248170</td>\n",
       "      <td>0.039149</td>\n",
       "      <td>-0.059893</td>\n",
       "      <td>-0.340883</td>\n",
       "      <td>-0.429343</td>\n",
       "      <td>-0.537162</td>\n",
       "      <td>0.121838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.527237</td>\n",
       "      <td>-1.149834</td>\n",
       "      <td>-0.385602</td>\n",
       "      <td>0.331072</td>\n",
       "      <td>1.192523</td>\n",
       "      <td>-0.723895</td>\n",
       "      <td>-0.482876</td>\n",
       "      <td>0.157595</td>\n",
       "      <td>0.957960</td>\n",
       "      <td>-0.913058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01</th>\n",
       "      <td>1.402303</td>\n",
       "      <td>1.502139</td>\n",
       "      <td>1.127752</td>\n",
       "      <td>1.433449</td>\n",
       "      <td>1.246867</td>\n",
       "      <td>1.440701</td>\n",
       "      <td>1.367405</td>\n",
       "      <td>1.270386</td>\n",
       "      <td>2.186734</td>\n",
       "      <td>1.630942</td>\n",
       "      <td>...</td>\n",
       "      <td>1.727693</td>\n",
       "      <td>1.844437</td>\n",
       "      <td>0.736191</td>\n",
       "      <td>1.195100</td>\n",
       "      <td>1.699285</td>\n",
       "      <td>-0.427417</td>\n",
       "      <td>0.635624</td>\n",
       "      <td>-0.805535</td>\n",
       "      <td>-0.804724</td>\n",
       "      <td>-0.851156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-02</th>\n",
       "      <td>0.691778</td>\n",
       "      <td>1.509598</td>\n",
       "      <td>0.995400</td>\n",
       "      <td>1.080868</td>\n",
       "      <td>1.191060</td>\n",
       "      <td>1.187973</td>\n",
       "      <td>0.226545</td>\n",
       "      <td>0.860312</td>\n",
       "      <td>2.288222</td>\n",
       "      <td>1.404747</td>\n",
       "      <td>...</td>\n",
       "      <td>1.320865</td>\n",
       "      <td>1.150398</td>\n",
       "      <td>1.312095</td>\n",
       "      <td>0.869575</td>\n",
       "      <td>1.440482</td>\n",
       "      <td>-0.532895</td>\n",
       "      <td>0.617429</td>\n",
       "      <td>-1.453804</td>\n",
       "      <td>-0.249547</td>\n",
       "      <td>-0.339102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-07</th>\n",
       "      <td>-0.513137</td>\n",
       "      <td>-0.020134</td>\n",
       "      <td>0.020299</td>\n",
       "      <td>-0.345851</td>\n",
       "      <td>0.241752</td>\n",
       "      <td>-0.180007</td>\n",
       "      <td>-0.681870</td>\n",
       "      <td>-0.986001</td>\n",
       "      <td>0.524322</td>\n",
       "      <td>-0.283805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.341533</td>\n",
       "      <td>-0.537381</td>\n",
       "      <td>0.948872</td>\n",
       "      <td>0.289577</td>\n",
       "      <td>-0.466110</td>\n",
       "      <td>-1.111572</td>\n",
       "      <td>-0.524792</td>\n",
       "      <td>-1.388810</td>\n",
       "      <td>0.199153</td>\n",
       "      <td>2.128009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-08</th>\n",
       "      <td>-1.628228</td>\n",
       "      <td>-1.820185</td>\n",
       "      <td>-0.847520</td>\n",
       "      <td>-1.362537</td>\n",
       "      <td>-1.093070</td>\n",
       "      <td>-1.081226</td>\n",
       "      <td>-2.175328</td>\n",
       "      <td>-0.904898</td>\n",
       "      <td>-1.223189</td>\n",
       "      <td>-1.004073</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.247416</td>\n",
       "      <td>-1.499600</td>\n",
       "      <td>0.679468</td>\n",
       "      <td>-0.348475</td>\n",
       "      <td>-1.614591</td>\n",
       "      <td>-1.061943</td>\n",
       "      <td>-0.538320</td>\n",
       "      <td>-0.860649</td>\n",
       "      <td>0.645606</td>\n",
       "      <td>2.593529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-09</th>\n",
       "      <td>-1.496674</td>\n",
       "      <td>-1.212780</td>\n",
       "      <td>-1.080574</td>\n",
       "      <td>-1.375314</td>\n",
       "      <td>-0.913968</td>\n",
       "      <td>-0.631554</td>\n",
       "      <td>-0.983964</td>\n",
       "      <td>-1.103125</td>\n",
       "      <td>-0.418237</td>\n",
       "      <td>-0.228847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104232</td>\n",
       "      <td>-1.184264</td>\n",
       "      <td>1.023969</td>\n",
       "      <td>-0.068507</td>\n",
       "      <td>-1.015966</td>\n",
       "      <td>-0.897742</td>\n",
       "      <td>-0.625467</td>\n",
       "      <td>-0.119547</td>\n",
       "      <td>1.312392</td>\n",
       "      <td>2.770366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1220 rows √ó 887 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "symbol_id       1101      1102      1103      1104      1108      1109  \\\n",
       "trade_date                                                               \n",
       "2020-04-01 -0.165141  0.396585  0.078443  0.089599 -0.619321 -0.148782   \n",
       "2020-04-06 -0.277162  0.299730  0.009240  0.353117 -0.010091  0.044924   \n",
       "2020-04-07 -0.386795 -0.370135 -0.196156  0.088294  0.371439 -0.151109   \n",
       "2020-04-08 -0.337903 -0.311649  0.183218 -0.299780  0.037332 -0.164683   \n",
       "2020-04-09 -0.309666 -0.202460 -0.103384 -0.248170  0.039149 -0.059893   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2025-04-01  1.402303  1.502139  1.127752  1.433449  1.246867  1.440701   \n",
       "2025-04-02  0.691778  1.509598  0.995400  1.080868  1.191060  1.187973   \n",
       "2025-04-07 -0.513137 -0.020134  0.020299 -0.345851  0.241752 -0.180007   \n",
       "2025-04-08 -1.628228 -1.820185 -0.847520 -1.362537 -1.093070 -1.081226   \n",
       "2025-04-09 -1.496674 -1.212780 -1.080574 -1.375314 -0.913968 -0.631554   \n",
       "\n",
       "symbol_id       1110      1201      1203      1210  ...      9939      9940  \\\n",
       "trade_date                                          ...                       \n",
       "2020-04-01 -0.933043 -0.686305 -0.901289 -0.731514  ... -0.416946  0.616390   \n",
       "2020-04-06  0.815303 -0.652765 -0.360477 -0.378793  ... -0.460243  0.036481   \n",
       "2020-04-07  0.292804 -0.508770 -0.557872  0.005393  ... -0.385102 -0.630818   \n",
       "2020-04-08 -0.697732 -0.454069 -0.728089  0.217207  ... -0.521642 -0.991485   \n",
       "2020-04-09 -0.340883 -0.429343 -0.537162  0.121838  ... -0.527237 -1.149834   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "2025-04-01  1.367405  1.270386  2.186734  1.630942  ...  1.727693  1.844437   \n",
       "2025-04-02  0.226545  0.860312  2.288222  1.404747  ...  1.320865  1.150398   \n",
       "2025-04-07 -0.681870 -0.986001  0.524322 -0.283805  ... -0.341533 -0.537381   \n",
       "2025-04-08 -2.175328 -0.904898 -1.223189 -1.004073  ... -0.247416 -1.499600   \n",
       "2025-04-09 -0.983964 -1.103125 -0.418237 -0.228847  ...  0.104232 -1.184264   \n",
       "\n",
       "symbol_id       9941      9942      9943      9944      9945      9946  \\\n",
       "trade_date                                                               \n",
       "2020-04-01  0.865555 -0.155905 -0.268315 -1.961625 -1.344977  0.984428   \n",
       "2020-04-06  0.434861 -0.045912  0.179594 -0.824940 -0.726843  3.296798   \n",
       "2020-04-07  0.216666 -0.017604 -0.245133 -1.081967 -0.760730  1.611201   \n",
       "2020-04-08  0.152767  0.299659  0.876070 -1.256489 -0.638734  0.623656   \n",
       "2020-04-09 -0.385602  0.331072  1.192523 -0.723895 -0.482876  0.157595   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2025-04-01  0.736191  1.195100  1.699285 -0.427417  0.635624 -0.805535   \n",
       "2025-04-02  1.312095  0.869575  1.440482 -0.532895  0.617429 -1.453804   \n",
       "2025-04-07  0.948872  0.289577 -0.466110 -1.111572 -0.524792 -1.388810   \n",
       "2025-04-08  0.679468 -0.348475 -1.614591 -1.061943 -0.538320 -0.860649   \n",
       "2025-04-09  1.023969 -0.068507 -1.015966 -0.897742 -0.625467 -0.119547   \n",
       "\n",
       "symbol_id       9955      9958  \n",
       "trade_date                      \n",
       "2020-04-01  0.483491 -0.488042  \n",
       "2020-04-06  0.899926 -0.943563  \n",
       "2020-04-07  1.893717 -1.222098  \n",
       "2020-04-08  1.738175 -0.584666  \n",
       "2020-04-09  0.957960 -0.913058  \n",
       "...              ...       ...  \n",
       "2025-04-01 -0.804724 -0.851156  \n",
       "2025-04-02 -0.249547 -0.339102  \n",
       "2025-04-07  0.199153  2.128009  \n",
       "2025-04-08  0.645606  2.593529  \n",
       "2025-04-09  1.312392  2.770366  \n",
       "\n",
       "[1220 rows x 887 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2af34e-da61-4360-b781-9aa4f0bdd514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9ce7539-b1de-4102-afa8-1419f58b41df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- ÂÖ±Áî®Âü∫Â∫ïÈ°ûÂà• ----------\n",
    "\n",
    "class BaseFeatureSelector:\n",
    "    def _knee_select(self, scores_sorted):\n",
    "        x = list(range(len(scores_sorted)))\n",
    "        y_score = scores_sorted.values\n",
    "        kn = KneeLocator(x, y_score, curve=\"convex\", direction=\"decreasing\")\n",
    "        elbow_idx = kn.knee if kn.knee is not None else 10  # fallback È†êË®≠ÈÅ∏Ââç10ÂÄã\n",
    "        return scores_sorted.iloc[:elbow_idx].index.tolist()\n",
    "\n",
    "# ---------- ÁâπÂæµÈÅ∏ÊìáÂô®ÂÄë ----------\n",
    "\n",
    "class XGBFeatureSelector(BaseFeatureSelector):\n",
    "    def select(self, model, X, y):\n",
    "        importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "        scores_sorted = importances.sort_values(ascending=False)\n",
    "        return self._knee_select(scores_sorted)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "class XGBFeatureSelector(BaseFeatureSelector):\n",
    "    def select(self, model, X, y):\n",
    "        importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "        scores_sorted = importances.sort_values(ascending=False)\n",
    "\n",
    "        self._plot_feature_scores(scores_sorted, title=\"XGBoost Feature Importance\")\n",
    "        return self._knee_select(scores_sorted)\n",
    "\n",
    "    def _plot_feature_scores(self, scores_sorted, title=\"Feature Importance + Elbow Point\"):\n",
    "        x = list(range(len(scores_sorted)))\n",
    "        y = scores_sorted.values\n",
    "\n",
    "        # ‰ΩøÁî® KneeLocator Êâæ elbow Èªû\n",
    "        kn = KneeLocator(x, y, curve=\"convex\", direction=\"decreasing\")\n",
    "        elbow_idx = kn.knee if kn.knee is not None else 10\n",
    "\n",
    "        # Áπ™Âúñ\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        plt.plot(x, y, marker='o', markersize=0.1 ,linewidth=1, label=\"Feature Score\")\n",
    "        plt.axvline(elbow_idx, color='red', linestyle='--', label=f'Elbow Point)')\n",
    "\n",
    "        # ‰∏çÈ°ØÁ§∫ X Ëª∏ÁâπÂæµÂêçÁ®±\n",
    "        plt.xlabel(\"Feature Rank\")  # Êàñ plt.xlabel(\"\") Â¶ÇÊûú‰Ω†ÈÄ£ÊñáÂ≠óÈÉΩ‰∏çË¶Å\n",
    "        plt.ylabel(\"Importance Score\")\n",
    "        plt.title(title)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class FRegressionFeatureSelector(BaseFeatureSelector):\n",
    "    def select(self, model, X, y):\n",
    "        f_scores, _ = f_regression(X, y)\n",
    "        scores = pd.Series(f_scores, index=X.columns).fillna(0)\n",
    "        scores_sorted = scores.sort_values(ascending=False)\n",
    "        return self._knee_select(scores_sorted)\n",
    "\n",
    "\n",
    "class MutualInfoFeatureSelector(BaseFeatureSelector):\n",
    "    def select(self, model, X, y):\n",
    "        mi_scores = mutual_info_regression(X, y, discrete_features='auto')\n",
    "        scores = pd.Series(mi_scores, index=X.columns).fillna(0)\n",
    "        scores_sorted = scores.sort_values(ascending=False)\n",
    "        return self._knee_select(scores_sorted)\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class LassoRegressionGPU(nn.Module):\n",
    "    def __init__(self, n_features, alpha=1.0):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(n_features, 1)\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "    def l1_penalty(self):\n",
    "        return torch.sum(torch.abs(self.linear.weight))\n",
    "\n",
    "class LassoFeatureSelectorGPU(BaseFeatureSelector):\n",
    "    def __init__(self, alpha=1.0, lr=0.01, epochs=1000):\n",
    "        self.alpha = alpha\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def select(self, model, X, y):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        X_tensor = torch.tensor(X.values, dtype=torch.float32).to(device)\n",
    "        y_tensor = torch.tensor(y.reshape(-1, 1), dtype=torch.float32).to(device)\n",
    "\n",
    "        model = LassoRegressionGPU(X.shape[1], alpha=self.alpha).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=self.lr)\n",
    "        loss_fn = nn.MSELoss()\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X_tensor)\n",
    "            loss = loss_fn(preds, y_tensor) + self.alpha * model.l1_penalty()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        weights = model.linear.weight.detach().cpu().numpy().flatten()\n",
    "        scores = pd.Series(abs(weights), index=X.columns).fillna(0)\n",
    "        scores_sorted = scores.sort_values(ascending=False)\n",
    "        return self._knee_select(scores_sorted)\n",
    "\n",
    "     \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "class ElasticNetRegressionGPU(nn.Module):\n",
    "    def __init__(self, n_features, alpha=1.0, l1_ratio=0.5):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(n_features, 1)\n",
    "        self.alpha = alpha\n",
    "        self.l1_ratio = l1_ratio  # 1.0 = Lasso, 0.0 = Ridge\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "    def elasticnet_penalty(self):\n",
    "        l1 = torch.sum(torch.abs(self.linear.weight))\n",
    "        l2 = torch.sum(self.linear.weight ** 2)\n",
    "        return self.l1_ratio * l1 + (1 - self.l1_ratio) * l2\n",
    "\n",
    "class ElasticNetFeatureSelectorGPU(BaseFeatureSelector):\n",
    "    def __init__(self, alpha=1.0, l1_ratio=0.5, lr=0.01, epochs=1000):\n",
    "        self.alpha = alpha\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def select(self, model, X, y):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        X_tensor = torch.tensor(X.values, dtype=torch.float32).to(device)\n",
    "        y_tensor = torch.tensor(y.reshape(-1, 1), dtype=torch.float32).to(device)\n",
    "\n",
    "        model = ElasticNetRegressionGPU(X.shape[1], alpha=self.alpha, l1_ratio=self.l1_ratio).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=self.lr)\n",
    "        loss_fn = nn.MSELoss()\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X_tensor)\n",
    "            loss = loss_fn(preds, y_tensor) + self.alpha * model.elasticnet_penalty()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        weights = model.linear.weight.detach().cpu().numpy().flatten()\n",
    "        scores = pd.Series(abs(weights), index=X.columns).fillna(0)\n",
    "        scores_sorted = scores.sort_values(ascending=False)\n",
    "        return self._knee_select(scores_sorted)\n",
    "\n",
    "\n",
    "\n",
    "# ---------- Ê®°ÂûãË®ìÁ∑¥‰∏ªÈ°ûÂà• ----------\n",
    "\n",
    "class XGBRegression:\n",
    "    def __init__(self, X_train, X_val, y_train, y_val, feature_selector):\n",
    "        self.X_train_full = X_train\n",
    "        self.X_val_full = X_val\n",
    "        self.y_train = y_train\n",
    "        self.y_val = y_val\n",
    "        self.feature_selector = feature_selector\n",
    "\n",
    "        # Ëã•ÊòØ XGB ÂûãÁâπÂæµÈÅ∏ÊìáÂô®ÔºåÈúÄË¶ÅÂÖàË®ìÁ∑¥Ê®°Âûã\n",
    "        pre_model = self._fit_model(X_train, y_train)\n",
    "\n",
    "        # ÁâπÂæµÈÅ∏Êìá\n",
    "        self.top_features = self.feature_selector.select(pre_model, X_train, y_train)\n",
    "\n",
    "        # Áî®ÈÅ∏Âá∫ÁöÑÁâπÂæµÈáçÊñ∞Ë®ìÁ∑¥Ê®°Âûã\n",
    "        self.model = self._fit_model(X_train[self.top_features], y_train)\n",
    "\n",
    "        # Ë®àÁÆóÈ©óË≠âÊêçÂ§±\n",
    "        self.loss = self._get_loss()\n",
    "\n",
    "    def _fit_model(self, X, y):\n",
    "        model = XGBRegressor(\n",
    "            tree_method=\"hist\",\n",
    "            device=\"cuda\",\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(X, y)\n",
    "        return model\n",
    "\n",
    "    def _get_loss(self):\n",
    "        y_pred = self.model.predict(self.X_val_full[self.top_features])\n",
    "        return mean_absolute_error(self.y_val, y_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40e1bfa1-e4ae-4a3e-bc8b-868fa0c7c2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "class PCAPreprocessor:\n",
    "    def __init__(self, n_splits=10, explained_var_threshold=0.99):\n",
    "        self.n_splits = n_splits\n",
    "        self.explained_var_threshold = explained_var_threshold\n",
    "        \n",
    "\n",
    "    def get_multidf_shift(self, n, multi_df):\n",
    "        new_columns = [(f\"{fac}_shift{n}\", tic) for fac, tic in multi_df.columns]\n",
    "        shifted = multi_df.copy()\n",
    "        shifted.columns = pd.MultiIndex.from_tuples(new_columns, names=[\"factor\", \"ticker\"])\n",
    "        return shifted.shift(n)\n",
    "\n",
    "    def get_all_multidf_shift(self, multi_df):\n",
    "        shifts = [self.get_multidf_shift(i, multi_df.copy()) for i in range(0, 9)]\n",
    "        all_shifted = pd.concat(shifts, axis=1).dropna(axis=0, how='any')\n",
    "        return all_shifted\n",
    "\n",
    "    def fit_pca(self, X, n_components):\n",
    "        from gpu_pca import IncrementalPCAonGPU\n",
    "        model = IncrementalPCAonGPU(n_components=n_components)\n",
    "        model.fit(X)\n",
    "        return model\n",
    "\n",
    "    def reduce_dimension(self, model, X):\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32).to(model.device)\n",
    "        reduced = model.transform(X_tensor).cpu().detach().numpy()\n",
    "        return reduced\n",
    "\n",
    "    def prepare_pca_dataframe(self, df_flat, reduced_X, index_99):\n",
    "        f_col_names = [f'PCA_factor_{j}' for j in range(index_99)]\n",
    "        df = pd.DataFrame(columns=['Date', 'ticker'] + f_col_names)\n",
    "        df['Date'] = df_flat['Date']\n",
    "        df['ticker'] = df_flat['ticker']\n",
    "        df[f_col_names] = reduced_X\n",
    "        return df.pivot(index='Date', columns='ticker')\n",
    "\n",
    "    def process_fold(self, i, train_idx, val_idx, factor_dataset, z_return_df):\n",
    "        # Ë£úÂº∑Ë≥áÊñô\n",
    "        val_idx = list(range(val_idx[0] - 8, val_idx[-1] + 1))\n",
    "\n",
    "        df_flat_train = (factor_dataset.multi_df.iloc[train_idx]\n",
    "            .stack(level='ticker', future_stack=True)\n",
    "            .reset_index()\n",
    "            .sort_values(by=['Date', 'ticker'])\n",
    "        )\n",
    "\n",
    "        df_flat_val = (factor_dataset.multi_df.iloc[val_idx]\n",
    "            .stack(level='ticker', future_stack=True)\n",
    "            .reset_index()\n",
    "            .sort_values(by=['Date', 'ticker'])\n",
    "        )\n",
    "\n",
    "        X_train = df_flat_train.drop(columns=['Date', 'ticker']).values\n",
    "        X_val = df_flat_val.drop(columns=['Date', 'ticker']).values\n",
    "\n",
    "        model_full = self.fit_pca(X_train, n_components=X_train.shape[1])\n",
    "        ratios = model_full.explained_variance_ratio_.cpu().numpy()\n",
    "        cum_ratios = np.cumsum(ratios) / np.sum(ratios)\n",
    "        index_99 = np.argmax(cum_ratios > self.explained_var_threshold) + 1\n",
    "\n",
    "        print(f'ÁØ©ÈÅ∏Âá∫{index_99}ÂÄãPCAÁâπÂæµ')\n",
    "\n",
    "        model_n = self.fit_pca(X_train, n_components=index_99)\n",
    "        X_train_reduced = self.reduce_dimension(model_n, X_train)\n",
    "        X_val_reduced = self.reduce_dimension(model_n, X_val)\n",
    "\n",
    "        pca_multidf_train = self.prepare_pca_dataframe(df_flat_train, X_train_reduced, index_99)\n",
    "        pca_multidf_val = self.prepare_pca_dataframe(df_flat_val, X_val_reduced, index_99)\n",
    "\n",
    "        all_multidf_train = self.get_all_multidf_shift(pca_multidf_train)\n",
    "        all_multidf_val = self.get_all_multidf_shift(pca_multidf_val)\n",
    "\n",
    "        train_stacked = (all_multidf_train.stack(level='ticker', future_stack=True)\n",
    "            .reset_index()\n",
    "            .sort_values(by=['Date', 'ticker'])\n",
    "            .drop(columns=['Date', 'ticker']))\n",
    "\n",
    "        start_dt, end_dt = all_multidf_train.index[0], all_multidf_train.index[-1]\n",
    "        r_train_array = z_return_df.loc[start_dt:end_dt].stack().sort_index().values\n",
    "\n",
    "        val_stacked = (all_multidf_val.stack(level='ticker', future_stack=True)\n",
    "            .reset_index()\n",
    "            .sort_values(by=['Date', 'ticker'])\n",
    "            .drop(columns=['Date', 'ticker']))\n",
    "\n",
    "        start_dt_val, end_dt_val = all_multidf_val.index[0], all_multidf_val.index[-1]\n",
    "        r_val_array = z_return_df.loc[start_dt_val:end_dt_val].stack().sort_index().values\n",
    "\n",
    "\n",
    "        return train_stacked, r_train_array, val_stacked, r_val_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89b377d1-7c88-419f-a55a-ee5c7f5fdcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "ÁØ©ÈÅ∏Âá∫80ÂÄãPCAÁâπÂæµ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dctp2025\\.conda\\envs\\dc1\\Lib\\site-packages\\xgboost\\core.py:729: UserWarning: [11:09:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB: 0.6372, 30 features\n",
      "FRegression: 0.6399, 45 features\n",
      "LASSO: 0.6378, 18 features\n",
      "Elastic: 0.6390, 42 features\n",
      "Fold 2\n",
      "ÁØ©ÈÅ∏Âá∫83ÂÄãPCAÁâπÂæµ\n",
      "XGB: 0.6518, 35 features\n",
      "FRegression: 0.6502, 50 features\n",
      "LASSO: 0.6522, 46 features\n",
      "Elastic: 0.6513, 45 features\n",
      "Fold 3\n",
      "ÁØ©ÈÅ∏Âá∫89ÂÄãPCAÁâπÂæµ\n",
      "XGB: 0.6495, 24 features\n",
      "FRegression: 0.6502, 22 features\n",
      "LASSO: 0.6498, 27 features\n",
      "Elastic: 0.6514, 20 features\n",
      "Fold 4\n",
      "ÁØ©ÈÅ∏Âá∫88ÂÄãPCAÁâπÂæµ\n",
      "XGB: 0.6413, 35 features\n",
      "FRegression: 0.6405, 42 features\n",
      "LASSO: 0.6409, 38 features\n",
      "Elastic: 0.6410, 32 features\n",
      "Fold 5\n",
      "ÁØ©ÈÅ∏Âá∫88ÂÄãPCAÁâπÂæµ\n",
      "XGB: 0.6600, 44 features\n",
      "FRegression: 0.6606, 43 features\n",
      "LASSO: 0.6603, 74 features\n",
      "Elastic: 0.6603, 12 features\n",
      "Fold 6\n",
      "ÁØ©ÈÅ∏Âá∫88ÂÄãPCAÁâπÂæµ\n",
      "XGB: 0.6585, 22 features\n",
      "FRegression: 0.6594, 40 features\n",
      "LASSO: 0.6581, 22 features\n",
      "Elastic: 0.6585, 55 features\n",
      "Fold 7\n",
      "ÁØ©ÈÅ∏Âá∫87ÂÄãPCAÁâπÂæµ\n",
      "XGB: 0.6316, 13 features\n",
      "FRegression: 0.6295, 27 features\n",
      "LASSO: 0.6313, 20 features\n",
      "Elastic: 0.6301, 8 features\n",
      "Fold 8\n",
      "ÁØ©ÈÅ∏Âá∫87ÂÄãPCAÁâπÂæµ\n",
      "XGB: 0.6300, 40 features\n",
      "FRegression: 0.6307, 26 features\n",
      "LASSO: 0.6307, 32 features\n",
      "Elastic: 0.6305, 24 features\n",
      "Fold 9\n",
      "ÁØ©ÈÅ∏Âá∫86ÂÄãPCAÁâπÂæµ\n",
      "XGB: 0.6439, 28 features\n",
      "FRegression: 0.6416, 39 features\n",
      "LASSO: 0.6437, 52 features\n",
      "Elastic: 0.6423, 55 features\n",
      "Fold 10\n",
      "ÁØ©ÈÅ∏Âá∫86ÂÄãPCAÁâπÂæµ\n",
      "XGB: 0.6499, 27 features\n",
      "FRegression: 0.6496, 38 features\n",
      "LASSO: 0.6497, 48 features\n",
      "Elastic: 0.6500, 16 features\n"
     ]
    }
   ],
   "source": [
    "# ÂÑ≤Â≠òÁµêÊûúÔºöÁî® defaultdict + listÔºåÁ∞°ÊΩîÁµ±‰∏Ä\n",
    "feature_results = defaultdict(list)\n",
    "loss_results = defaultdict(list)\n",
    "# ÁâπÂæµÈÅ∏ÊìáÂô®ÂÆöÁæ©\n",
    "SELECTORS = {\n",
    "    'XGB': XGBFeatureSelector(),\n",
    "    'FRegression': FRegressionFeatureSelector(),\n",
    "    'LASSO': LassoFeatureSelectorGPU(alpha=0.1, epochs=500),\n",
    "    'Elastic': ElasticNetFeatureSelectorGPU(alpha=0.01, l1_ratio=0.7, epochs=500)\n",
    "}\n",
    "# ÊäΩÂá∫ÊØèÁ®ÆÁâπÂæµÈÅ∏ÊìáÁµêÊûú\n",
    "def get_feature_result(selector_name, X_train, X_val, y_train, y_val):\n",
    "    selector = SELECTORS[selector_name]\n",
    "    model = XGBRegression(X_train, X_val, y_train, y_val, feature_selector=selector)\n",
    "    return model.top_features, model.loss\n",
    "# ÊôÇÂ∫è‰∫§ÂèâÈ©óË≠â\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "# PCA Preprocessor\n",
    "preprocessor = PCAPreprocessor()\n",
    "\n",
    "\n",
    "restrict_start, restrict_end = '2020-04-01', '2024-09-30'\n",
    "\n",
    "\"\"\"\n",
    "Âè™ËÉΩÂú®trainsetÁØÑÂúçÂÖßÂÅöTimesplitCrossValidation\n",
    "(restrict_start, restrict_end)\n",
    "\"\"\"\n",
    "\n",
    "for i, (train_idx, val_idx) in enumerate(tscv.split(factor_dataset.multi_df.loc[restrict_start:restrict_end])):\n",
    "    print(f\"Fold {i + 1}\")\n",
    "    result = preprocessor.process_fold(i, train_idx, val_idx, factor_dataset, z_return_df)\n",
    "    X_train, y_train, X_val, y_val = result\n",
    "    \n",
    "\n",
    "    for name in SELECTORS.keys():\n",
    "        try:\n",
    "            top_features, loss = get_feature_result(name, X_train, X_val, y_train, y_val)\n",
    "            feature_results[name].append(top_features)\n",
    "            loss_results[name].append(loss)\n",
    "            print(f\"{name}: {loss:.4f}, {len(top_features)} features\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå {name} failed: {e}\")\n",
    "\n",
    "      # Â¶ÇÈúÄÂÖ®Ë∑ëÂèØÁßªÈô§\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3f55b1-73f0-4b1a-9d57-efb9b59e77d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pca_num_list = [80,83,89,88,88,88,87,87,86,86]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bca4e1a-6f0b-477f-b8f7-fe71e52530d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Á≥ªÁµ±Á∏ΩË®òÊÜ∂È´î: 65298.48 MB\n",
      "üü¢ Áï∂ÂâçÂèØÁî®Ë®òÊÜ∂È´î: 33635.85 MB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "mem = psutil.virtual_memory()\n",
    "\n",
    "total_MB = mem.total / 1024 / 1024\n",
    "available_MB = mem.available / 1024 / 1024\n",
    "\n",
    "print(f\"‚úÖ Á≥ªÁµ±Á∏ΩË®òÊÜ∂È´î: {total_MB:.2f} MB\")\n",
    "print(f\"üü¢ Áï∂ÂâçÂèØÁî®Ë®òÊÜ∂È´î: {available_MB:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09900d3a-35e5-4c82-9045-5fcd47475da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "81bd7baa-1533-4e71-a179-08018a2e2543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "455bb4aa-f124-4d61-8ab9-dc9c73bacde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Selector  MAE Mean   MAE Std  MAE Mean / Std\n",
      "2        LASSO  0.645199  0.009801       65.829817\n",
      "1  FRegression  0.645215  0.010141       63.625243\n",
      "3      Elastic  0.645258  0.010306       62.607741\n",
      "0          XGB  0.645369  0.009890       65.252973\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Êî∂ÈõÜÁµ±Ë®àÁµêÊûú\n",
    "summary = []\n",
    "\n",
    "for name, losses in loss_results.items():\n",
    "    mae_mean = np.mean(losses)\n",
    "    mae_std = np.std(losses)\n",
    "    mae_to_std = mae_mean / mae_std if mae_std > 0 else np.inf\n",
    "\n",
    "    summary.append({\n",
    "        'Selector': name,\n",
    "        'MAE Mean': mae_mean,\n",
    "        'MAE Std': mae_std,\n",
    "        'MAE Mean / Std': mae_to_std\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary).sort_values(by='MAE Mean')\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e97dc8b7-a91e-4970-9407-b22fdadcd13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'XGB': [0.6371521652280511,\n",
       "              0.6518391206075661,\n",
       "              0.649466554097214,\n",
       "              0.6412612480876408,\n",
       "              0.6599712763248164,\n",
       "              0.6585298825669097,\n",
       "              0.6316433739986268,\n",
       "              0.6299590613687208,\n",
       "              0.6439396595265641,\n",
       "              0.6499289862859381],\n",
       "             'FRegression': [0.6398752897588575,\n",
       "              0.6502249588099752,\n",
       "              0.6502253080225091,\n",
       "              0.6404678686507277,\n",
       "              0.6605854326012626,\n",
       "              0.6593803803173828,\n",
       "              0.6295238863225311,\n",
       "              0.6306534043977898,\n",
       "              0.641628809671446,\n",
       "              0.6495854653051842],\n",
       "             'LASSO': [0.6377775713605365,\n",
       "              0.6522308616926162,\n",
       "              0.649828604424157,\n",
       "              0.6408839961129676,\n",
       "              0.6603473505575431,\n",
       "              0.6580647777695662,\n",
       "              0.6312919068148891,\n",
       "              0.6307112328002469,\n",
       "              0.6436661832292314,\n",
       "              0.6497392854783481],\n",
       "             'Elastic': [0.6389762115774059,\n",
       "              0.651261918294484,\n",
       "              0.6514216513869159,\n",
       "              0.6409722782970327,\n",
       "              0.660345842168268,\n",
       "              0.658503978817702,\n",
       "              0.6301284399000819,\n",
       "              0.6304705544071809,\n",
       "              0.6422623321930919,\n",
       "              0.6500009649763783]})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2ff45840-5c89-45e5-b06a-2f08a984c9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friedman statistic: 0.1200\n",
      "p-value: 0.9893\n",
      "‚ùå ‰∏çÂêåÊ®°Âûã‰πãÈñìÂú® MAE ‰∏äÊ≤íÊúâÈ°ØËëóÂ∑ÆÁï∞\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "stat, p = friedmanchisquare(\n",
    "    loss_results['XGB'],\n",
    "    loss_results['FRegression'],\n",
    "    loss_results['LASSO'],\n",
    "    loss_results['Elastic']\n",
    ")\n",
    "\n",
    "print(f\"Friedman statistic: {stat:.4f}\")\n",
    "print(f\"p-value: {p:.4f}\")\n",
    "\n",
    "if p < 0.05:\n",
    "    print(\"‚úÖ ‰∏çÂêåÊ®°Âûã‰πãÈñìÂú® MAE ‰∏äÂ≠òÂú®È°ØËëóÂ∑ÆÁï∞\")\n",
    "else:\n",
    "    print(\"‚ùå ‰∏çÂêåÊ®°Âûã‰πãÈñìÂú® MAE ‰∏äÊ≤íÊúâÈ°ØËëóÂ∑ÆÁï∞\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6b63f743-6420-4211-9cf5-c536853d9a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB</th>\n",
       "      <th>FRegression</th>\n",
       "      <th>LASSO</th>\n",
       "      <th>Elastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998155</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRegression</th>\n",
       "      <td>0.998155</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998155</td>\n",
       "      <td>0.985723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998155</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elastic</th>\n",
       "      <td>0.998155</td>\n",
       "      <td>0.985723</td>\n",
       "      <td>0.998155</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  XGB  FRegression     LASSO   Elastic\n",
       "XGB          1.000000     0.998155  1.000000  0.998155\n",
       "FRegression  0.998155     1.000000  0.998155  0.985723\n",
       "LASSO        1.000000     0.998155  1.000000  0.998155\n",
       "Elastic      0.998155     0.985723  0.998155  1.000000"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scikit_posthocs as sp\n",
    "import pandas as pd\n",
    "\n",
    "# ÁµÑÊàê dfÔºåÊØèÊ¨ÑÊòØÊ®°ÂûãÔºåÊØèÂàóÊòØ fold\n",
    "data = pd.DataFrame(loss_results)\n",
    "sp.posthoc_nemenyi_friedman(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513603c6-1e78-4fcd-a575-52ecbab2ac1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
