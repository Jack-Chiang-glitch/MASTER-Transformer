{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7202a21-2afe-48c7-a48d-1cd30fa0a31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from library import StockUniverse, FactorLibrary, MarketInfo, FileLoader\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import gc\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#from model import MASTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc9a070-8e7b-4e5d-b852-998ef1178765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>factor</th>\n",
       "      <th colspan=\"10\" halign=\"left\">factor_0</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">factor_185</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th>1101</th>\n",
       "      <th>1102</th>\n",
       "      <th>1103</th>\n",
       "      <th>1104</th>\n",
       "      <th>1108</th>\n",
       "      <th>1109</th>\n",
       "      <th>1110</th>\n",
       "      <th>1201</th>\n",
       "      <th>1203</th>\n",
       "      <th>1210</th>\n",
       "      <th>...</th>\n",
       "      <th>9944</th>\n",
       "      <th>9945</th>\n",
       "      <th>9946</th>\n",
       "      <th>9949</th>\n",
       "      <th>9950</th>\n",
       "      <th>9951</th>\n",
       "      <th>9955</th>\n",
       "      <th>9958</th>\n",
       "      <th>9960</th>\n",
       "      <th>9962</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-04-01</th>\n",
       "      <td>-0.204447</td>\n",
       "      <td>0.205286</td>\n",
       "      <td>-0.066181</td>\n",
       "      <td>0.698856</td>\n",
       "      <td>5.904405e+00</td>\n",
       "      <td>-7.561437e-01</td>\n",
       "      <td>-1.967005</td>\n",
       "      <td>3.591879</td>\n",
       "      <td>0.800305</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999935</td>\n",
       "      <td>0.993475</td>\n",
       "      <td>1.006718</td>\n",
       "      <td>0.995031</td>\n",
       "      <td>0.998105</td>\n",
       "      <td>1.000538</td>\n",
       "      <td>1.000069</td>\n",
       "      <td>1.000420</td>\n",
       "      <td>0.999717</td>\n",
       "      <td>0.998158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-06</th>\n",
       "      <td>1.677682</td>\n",
       "      <td>2.064220</td>\n",
       "      <td>1.186552</td>\n",
       "      <td>2.021478</td>\n",
       "      <td>4.580153e+00</td>\n",
       "      <td>7.532957e-01</td>\n",
       "      <td>-2.742347</td>\n",
       "      <td>1.634321</td>\n",
       "      <td>0.190114</td>\n",
       "      <td>0.514766</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000702</td>\n",
       "      <td>0.993183</td>\n",
       "      <td>1.002554</td>\n",
       "      <td>1.001527</td>\n",
       "      <td>0.993129</td>\n",
       "      <td>1.001826</td>\n",
       "      <td>1.000605</td>\n",
       "      <td>0.999211</td>\n",
       "      <td>1.000621</td>\n",
       "      <td>1.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-07</th>\n",
       "      <td>3.574125</td>\n",
       "      <td>6.542993</td>\n",
       "      <td>3.583062</td>\n",
       "      <td>3.932584</td>\n",
       "      <td>3.720238e+00</td>\n",
       "      <td>2.684145e+00</td>\n",
       "      <td>-1.923077</td>\n",
       "      <td>0.899101</td>\n",
       "      <td>0.720789</td>\n",
       "      <td>0.862999</td>\n",
       "      <td>...</td>\n",
       "      <td>1.003852</td>\n",
       "      <td>1.000872</td>\n",
       "      <td>0.992585</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>0.992867</td>\n",
       "      <td>1.003646</td>\n",
       "      <td>1.000810</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>1.000332</td>\n",
       "      <td>1.003496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-08</th>\n",
       "      <td>1.803156</td>\n",
       "      <td>3.897716</td>\n",
       "      <td>2.580645</td>\n",
       "      <td>3.086420</td>\n",
       "      <td>1.167883e+00</td>\n",
       "      <td>1.863354e+00</td>\n",
       "      <td>-0.388098</td>\n",
       "      <td>0.647733</td>\n",
       "      <td>0.830816</td>\n",
       "      <td>0.861837</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006097</td>\n",
       "      <td>1.000800</td>\n",
       "      <td>0.997986</td>\n",
       "      <td>0.999393</td>\n",
       "      <td>0.998528</td>\n",
       "      <td>1.004831</td>\n",
       "      <td>0.998951</td>\n",
       "      <td>1.002109</td>\n",
       "      <td>1.003819</td>\n",
       "      <td>1.003078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-09</th>\n",
       "      <td>1.612903</td>\n",
       "      <td>2.657888</td>\n",
       "      <td>2.171137</td>\n",
       "      <td>2.251978</td>\n",
       "      <td>7.163324e-01</td>\n",
       "      <td>1.600985e+00</td>\n",
       "      <td>1.552393</td>\n",
       "      <td>1.045296</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>1.099490</td>\n",
       "      <td>...</td>\n",
       "      <td>1.003150</td>\n",
       "      <td>1.000016</td>\n",
       "      <td>1.003579</td>\n",
       "      <td>1.001872</td>\n",
       "      <td>1.001097</td>\n",
       "      <td>1.003353</td>\n",
       "      <td>0.998678</td>\n",
       "      <td>1.000542</td>\n",
       "      <td>1.004274</td>\n",
       "      <td>0.998203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-11</th>\n",
       "      <td>0.201748</td>\n",
       "      <td>1.637873</td>\n",
       "      <td>2.076125</td>\n",
       "      <td>0.662495</td>\n",
       "      <td>1.416853e+00</td>\n",
       "      <td>1.234568e+00</td>\n",
       "      <td>-1.020987</td>\n",
       "      <td>0.555213</td>\n",
       "      <td>2.632279</td>\n",
       "      <td>1.587874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996059</td>\n",
       "      <td>0.998892</td>\n",
       "      <td>0.995357</td>\n",
       "      <td>1.000269</td>\n",
       "      <td>0.997555</td>\n",
       "      <td>1.000148</td>\n",
       "      <td>0.998767</td>\n",
       "      <td>0.991700</td>\n",
       "      <td>1.004853</td>\n",
       "      <td>0.999544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-14</th>\n",
       "      <td>0.435949</td>\n",
       "      <td>0.178691</td>\n",
       "      <td>2.739726</td>\n",
       "      <td>1.645338</td>\n",
       "      <td>1.694915e+00</td>\n",
       "      <td>2.932193e+00</td>\n",
       "      <td>2.362205</td>\n",
       "      <td>2.342787</td>\n",
       "      <td>1.968504</td>\n",
       "      <td>3.183119</td>\n",
       "      <td>...</td>\n",
       "      <td>1.001241</td>\n",
       "      <td>1.000427</td>\n",
       "      <td>0.996200</td>\n",
       "      <td>0.997938</td>\n",
       "      <td>0.994582</td>\n",
       "      <td>0.998891</td>\n",
       "      <td>0.998162</td>\n",
       "      <td>0.990563</td>\n",
       "      <td>0.996839</td>\n",
       "      <td>1.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-15</th>\n",
       "      <td>-1.298269</td>\n",
       "      <td>-1.757899</td>\n",
       "      <td>-0.539447</td>\n",
       "      <td>-1.377810</td>\n",
       "      <td>7.251632e-02</td>\n",
       "      <td>1.501502e+00</td>\n",
       "      <td>0.788288</td>\n",
       "      <td>-0.972053</td>\n",
       "      <td>0.388098</td>\n",
       "      <td>1.405975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998429</td>\n",
       "      <td>1.000944</td>\n",
       "      <td>1.001255</td>\n",
       "      <td>0.995323</td>\n",
       "      <td>0.999422</td>\n",
       "      <td>1.000020</td>\n",
       "      <td>0.999618</td>\n",
       "      <td>0.994872</td>\n",
       "      <td>0.996795</td>\n",
       "      <td>1.001954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-16</th>\n",
       "      <td>-1.143241</td>\n",
       "      <td>-0.826446</td>\n",
       "      <td>-0.473934</td>\n",
       "      <td>-0.693684</td>\n",
       "      <td>-7.267442e-02</td>\n",
       "      <td>3.605769e-01</td>\n",
       "      <td>-0.113186</td>\n",
       "      <td>-1.098901</td>\n",
       "      <td>-0.438483</td>\n",
       "      <td>2.019499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999026</td>\n",
       "      <td>1.000255</td>\n",
       "      <td>1.005863</td>\n",
       "      <td>0.995549</td>\n",
       "      <td>1.001755</td>\n",
       "      <td>1.001636</td>\n",
       "      <td>1.003275</td>\n",
       "      <td>0.999744</td>\n",
       "      <td>0.999842</td>\n",
       "      <td>1.002569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-17</th>\n",
       "      <td>-1.658768</td>\n",
       "      <td>0.044763</td>\n",
       "      <td>0.473613</td>\n",
       "      <td>0.365631</td>\n",
       "      <td>-2.664535e-13</td>\n",
       "      <td>2.886580e-13</td>\n",
       "      <td>-1.352875</td>\n",
       "      <td>-0.674433</td>\n",
       "      <td>-0.438483</td>\n",
       "      <td>1.038062</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002929</td>\n",
       "      <td>1.000698</td>\n",
       "      <td>1.004786</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997236</td>\n",
       "      <td>1.000412</td>\n",
       "      <td>1.001498</td>\n",
       "      <td>1.000800</td>\n",
       "      <td>0.997688</td>\n",
       "      <td>1.000966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1226 rows Ã— 328667 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "factor      factor_0                                              \\\n",
       "ticker          1101      1102      1103      1104          1108   \n",
       "Date                                                               \n",
       "2020-04-01 -0.204447  0.205286 -0.066181  0.698856  5.904405e+00   \n",
       "2020-04-06  1.677682  2.064220  1.186552  2.021478  4.580153e+00   \n",
       "2020-04-07  3.574125  6.542993  3.583062  3.932584  3.720238e+00   \n",
       "2020-04-08  1.803156  3.897716  2.580645  3.086420  1.167883e+00   \n",
       "2020-04-09  1.612903  2.657888  2.171137  2.251978  7.163324e-01   \n",
       "...              ...       ...       ...       ...           ...   \n",
       "2025-04-11  0.201748  1.637873  2.076125  0.662495  1.416853e+00   \n",
       "2025-04-14  0.435949  0.178691  2.739726  1.645338  1.694915e+00   \n",
       "2025-04-15 -1.298269 -1.757899 -0.539447 -1.377810  7.251632e-02   \n",
       "2025-04-16 -1.143241 -0.826446 -0.473934 -0.693684 -7.267442e-02   \n",
       "2025-04-17 -1.658768  0.044763  0.473613  0.365631 -2.664535e-13   \n",
       "\n",
       "factor                                                            ...  \\\n",
       "ticker              1109      1110      1201      1203      1210  ...   \n",
       "Date                                                              ...   \n",
       "2020-04-01 -7.561437e-01 -1.967005  3.591879  0.800305  1.369863  ...   \n",
       "2020-04-06  7.532957e-01 -2.742347  1.634321  0.190114  0.514766  ...   \n",
       "2020-04-07  2.684145e+00 -1.923077  0.899101  0.720789  0.862999  ...   \n",
       "2020-04-08  1.863354e+00 -0.388098  0.647733  0.830816  0.861837  ...   \n",
       "2020-04-09  1.600985e+00  1.552393  1.045296  1.315789  1.099490  ...   \n",
       "...                  ...       ...       ...       ...       ...  ...   \n",
       "2025-04-11  1.234568e+00 -1.020987  0.555213  2.632279  1.587874  ...   \n",
       "2025-04-14  2.932193e+00  2.362205  2.342787  1.968504  3.183119  ...   \n",
       "2025-04-15  1.501502e+00  0.788288 -0.972053  0.388098  1.405975  ...   \n",
       "2025-04-16  3.605769e-01 -0.113186 -1.098901 -0.438483  2.019499  ...   \n",
       "2025-04-17  2.886580e-13 -1.352875 -0.674433 -0.438483  1.038062  ...   \n",
       "\n",
       "factor     factor_185                                                    \\\n",
       "ticker           9944      9945      9946      9949      9950      9951   \n",
       "Date                                                                      \n",
       "2020-04-01   0.999935  0.993475  1.006718  0.995031  0.998105  1.000538   \n",
       "2020-04-06   1.000702  0.993183  1.002554  1.001527  0.993129  1.001826   \n",
       "2020-04-07   1.003852  1.000872  0.992585  0.999707  0.992867  1.003646   \n",
       "2020-04-08   1.006097  1.000800  0.997986  0.999393  0.998528  1.004831   \n",
       "2020-04-09   1.003150  1.000016  1.003579  1.001872  1.001097  1.003353   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "2025-04-11   0.996059  0.998892  0.995357  1.000269  0.997555  1.000148   \n",
       "2025-04-14   1.001241  1.000427  0.996200  0.997938  0.994582  0.998891   \n",
       "2025-04-15   0.998429  1.000944  1.001255  0.995323  0.999422  1.000020   \n",
       "2025-04-16   0.999026  1.000255  1.005863  0.995549  1.001755  1.001636   \n",
       "2025-04-17   1.002929  1.000698  1.004786  1.000000  0.997236  1.000412   \n",
       "\n",
       "factor                                              \n",
       "ticker          9955      9958      9960      9962  \n",
       "Date                                                \n",
       "2020-04-01  1.000069  1.000420  0.999717  0.998158  \n",
       "2020-04-06  1.000605  0.999211  1.000621  1.000076  \n",
       "2020-04-07  1.000810  0.999887  1.000332  1.003496  \n",
       "2020-04-08  0.998951  1.002109  1.003819  1.003078  \n",
       "2020-04-09  0.998678  1.000542  1.004274  0.998203  \n",
       "...              ...       ...       ...       ...  \n",
       "2025-04-11  0.998767  0.991700  1.004853  0.999544  \n",
       "2025-04-14  0.998162  0.990563  0.996839  1.000758  \n",
       "2025-04-15  0.999618  0.994872  0.996795  1.001954  \n",
       "2025-04-16  1.003275  0.999744  0.999842  1.002569  \n",
       "2025-04-17  1.001498  1.000800  0.997688  1.000966  \n",
       "\n",
       "[1226 rows x 328667 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FactorLibrary.multi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4988cdd6-60c8-466a-9811-665c88075e80",
   "metadata": {},
   "source": [
    "# ä¸‹ä¸€æ­¥æ˜¯ä¾ç…§TEST VALID TESTå»åŠƒåˆ†æ™‚é–“å€æ®µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d8471f8-b4df-4b12-97eb-3064871f613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AllDayFactorDataset(Dataset):\n",
    "    def __init__(self, stock_universe='TWSE'):\n",
    "        self.multi_df = FileLoader.load(f'Y:\\å› å­å›æ¸¬_æ±Ÿå»ºå½°\\å› å­åº«{stock_universe}.pkl')\n",
    "        self.adj_close_df = pd.read_feather(r'Y:\\å› å­å›æ¸¬_æ±Ÿå»ºå½°\\è£œä¸Šç¼ºå€¼æ—¥é »æ”¶ç›¤åƒ¹.ftr')\n",
    "        self.stock_list = self.get_stock_list(stock_universe)\n",
    "        \n",
    "        self.TPEX_df = MarketInfo.TPEX_norm()\n",
    "        self.RoR_df = (self.adj_close_df.shift(-5) - self.adj_close_df.shift(-1)) / self.adj_close_df.shift(-1)\n",
    "        self.RoR_df.dropna(axis=0, inplace=True)\n",
    "\n",
    "\n",
    "        new_ticker_list = self.multi_df.columns.get_level_values('ticker')\n",
    "        new_ticker_list = new_ticker_list[~new_ticker_list.duplicated()]\n",
    "\n",
    "        self.stock_list = new_ticker_list\n",
    "        self.RoR_df = self.RoR_df[self.stock_list]\n",
    "        # é€™è£¡æ‰€æœ‰å€¼éƒ½åŒ…å«ç•¶å¤©è³‡è¨Šæ‰€ä»¥è¦å‘å¾Œç§»\n",
    "        self.restrict_range()\n",
    "        self.check_validility()\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        #self.tensor_factor = self.factor_to_tensor()\n",
    "        #self.tensor_market = self.TPEX_df.values\n",
    "        #self.tensor_return = self.RoR_df[self.stock_list]\n",
    "        #print(f'stock list : {len(self.stock_list)}')\n",
    "    def check_validility(self):\n",
    "        ticker_list1 = self.stock_list\n",
    "        ticker_list2 = self.RoR_df.columns\n",
    "        ticker_list3 = self.multi_df.columns.get_level_values('ticker')\n",
    "        ticker_list3 = ticker_list3[~ticker_list3.duplicated()]\n",
    "        assert len(ticker_list1)==len(ticker_list2)==len(ticker_list3)\n",
    "        \n",
    "        BOOL = True\n",
    "        for i in range(len(ticker_list1)):\n",
    "            if not (ticker_list1[i]==ticker_list2[i]==ticker_list3[i]):\n",
    "                BOOL = False\n",
    "        assert BOOL==True\n",
    "        \n",
    "\n",
    "        factor_list = self.multi_df.columns.get_level_values('factor')\n",
    "        factor_list = factor_list[~factor_list.duplicated()]\n",
    "        BOOL = True\n",
    "        for factor_name in factor_list:\n",
    "            ticker_list4 = self.multi_df.loc[ : , factor_name].columns\n",
    "            for i in range(len(ticker_list1)):\n",
    "                if ticker_list1[i]!=ticker_list4[i]:\n",
    "                    BOOL = False\n",
    "        assert BOOL==True\n",
    "        \n",
    "\n",
    "    def factor_to_tensor(self):\n",
    "        factor_num = len(self.multi_df.columns.get_level_values('factor').unique())\n",
    "        time = len(self.TPEX_df.index)\n",
    "        \n",
    "\n",
    "       \n",
    "            \n",
    "            \n",
    "                \n",
    "        \"\"\"\n",
    "        å‰”é™¤å› å­ç¼ºå¤±å¤ªå¤šçš„è‚¡ç¥¨\n",
    "        \n",
    "        new_stock_list = []\n",
    "        for idx, ticker in enumerate(self.stock_list):\n",
    "            numpy_array = self.multi_df.xs(ticker, axis=1, level='ticker').values\n",
    "            missing_ratio = np.isnan(numpy_array).sum() / (time*factor_num)\n",
    "            if(missing_ratio<=0.05):\n",
    "                new_stock_list.append(ticker)\n",
    "        self.stock_list = new_stock_list\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        è½‰æˆå‘é‡\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        factor_name = 'factor1'\n",
    "        #print(self.multi_df.loc[start_date : end_date, factor_name])\n",
    "\n",
    "        \n",
    "        stock_num = len(self.stock_list)\n",
    "        tensor_factor = np.empty((stock_num, time, factor_num))\n",
    "        for idx, ticker in enumerate(self.stock_list):\n",
    "            numpy_array = self.multi_df.xs(ticker, axis=1, level='ticker').ffill().values\n",
    "            numpy_array = np.nan_to_num(numpy_array, nan=0.0)\n",
    "            tensor_factor[idx] = numpy_array\n",
    "\n",
    "        \n",
    "        \n",
    "        return tensor_factor\n",
    "\n",
    "    \n",
    "\n",
    "    def restrict_range(self, global_start='2020-04-01', global_end='2025-04-09'):\n",
    "        self.multi_df     = self.multi_df.loc[global_start : global_end]\n",
    "        self.adj_close_df = self.adj_close_df.loc[global_start : global_end]\n",
    "        self.TPEX_df      = self.TPEX_df.loc[global_start : global_end]\n",
    "        self.RoR_df       = self.RoR_df.loc[global_start : global_end]\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_stock_list(self, stock_univserse):\n",
    "        if stock_univserse=='TWSE':\n",
    "            ticker1 = StockUniverse.TWSE() \n",
    "        elif stock_univserse=='OTC':\n",
    "            ticker1 = StockUniverse.OTC()\n",
    "        elif stock_univserse=='all':\n",
    "            ticker1 = StockUniverse.all()\n",
    "            \n",
    "        \n",
    "        ticker2 = self.multi_df.columns.get_level_values('ticker')\n",
    "        ticker3 = self.adj_close_df.columns\n",
    "        return list(set(ticker1)&set(ticker2)&set(ticker3))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c79c5ab9-b130-4acb-8908-2fe60c9eb852",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorDataset(Dataset):\n",
    "    def __init__(self, stock_universe='TWSE', mode='train'):\n",
    "        #multi_df, TPEX_df, RoR_df = self.restrict_data_range(stock_universe, mode)\n",
    "        self.e = AllDayFactorDataset(stock_universe='TWSE')\n",
    "        self.stock_list = self.e.stock_list\n",
    "        multi_df, TPEX_df, RoR_df = self.restrict_data_range(stock_universe, mode)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.tensor_factor = self.get_tensor_factors(multi_df)\n",
    "        #self.tesnor_factor = self.tesnor_factor.transpose(1,0,2) # (stock, time, factor) -> (time, stock, factor)\n",
    "        self.tensor_market = TPEX_df.values\n",
    "        self.tensor_return = RoR_df.values\n",
    "\n",
    "        self.tensor_factor = self.transform_to_tensor(self.tensor_factor)\n",
    "        self.tensor_market = self.transform_to_tensor(self.tensor_market)\n",
    "        self.tensor_return = self.transform_to_tensor(self.tensor_return)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        returns = self.tensor_return.clone()  # shape: [122, 887]\n",
    "        mean = returns.mean(dim=1, keepdim=True)   # æ¯å¤©çš„å‡å€¼ shape: [122, 1]\n",
    "        std = returns.std(dim=1, keepdim=True)     # æ¯å¤©çš„æ¨™æº–å·® shape: [122, 1]\n",
    "        # é˜²æ­¢é™¤ä»¥ 0\n",
    "        std = torch.where(std == 0, torch.tensor(1.0), std)\n",
    "        self.tensor_return_norm = (returns - mean) / std  # shape: [122, 887]\n",
    "\n",
    "\n",
    "        self.T = self.tensor_market.shape[0]\n",
    "        self.lookback = 8\n",
    "        self.valid_length = self.T - self.lookback\n",
    "\n",
    "        del self.e\n",
    "        gc.collect()\n",
    "        \n",
    "    def transform_to_tensor(self, numpy_array):\n",
    "        float32_np = numpy_array.astype(np.float32)\n",
    "        return torch.from_numpy(float32_np)\n",
    "\n",
    "    def get_tensor_factors(self, multi_df):\n",
    "        stock_num = len(multi_df.columns.get_level_values('ticker').unique())\n",
    "        time = len(multi_df.index)\n",
    "        factor_num = len(multi_df.columns.get_level_values('factor').unique())\n",
    "        \n",
    "        tensor_factor = np.empty((stock_num, time, factor_num))\n",
    "        for idx, ticker in enumerate(self.stock_list):\n",
    "            numpy_array = multi_df.xs(ticker, axis=1, level='ticker').values\n",
    "            tensor_factor[idx] = numpy_array\n",
    "\n",
    "        assert not np.isnan(tensor_factor).any()\n",
    "\n",
    "        return tensor_factor\n",
    "        \n",
    "\n",
    "    def restrict_data_range(self, stock_universe, mode):\n",
    "        e = AllDayFactorDataset(stock_universe)\n",
    "        train_ratio, valid_ratio, test_ratio = 0.8, 0.1, 0.1\n",
    "        total_num = len(self.e.TPEX_df)\n",
    "        train_num = int(total_num*train_ratio)\n",
    "        valid_num = int(total_num*valid_ratio)\n",
    "        test_num  = total_num - (train_num+valid_num)\n",
    "        if mode=='train':\n",
    "            start_idx, end_idx = 0, train_num\n",
    "        elif mode=='valid':\n",
    "            start_idx, end_idx = train_num, train_num + valid_num\n",
    "        elif mode=='test': \n",
    "            start_idx, end_idx = train_num + valid_num, total_num\n",
    "\n",
    "        e = AllDayFactorDataset(stock_universe)\n",
    "        return self.e.multi_df.iloc[start_idx : end_idx], \\\n",
    "               self.e.TPEX_df.iloc[start_idx : end_idx], \\\n",
    "               self.e.RoR_df.iloc[start_idx : end_idx]\n",
    "    def __len__(self):\n",
    "        return self.valid_length\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.tensor_factor[ : , idx:idx+self.lookback, : ] # (stock, time, factor)\n",
    "        M = self.tensor_market[idx+self.lookback-1, : ]\n",
    "        R = self.tensor_return[idx+self.lookback-1, : ]\n",
    "        R_norm = self.tensor_return_norm[idx+self.lookback-1, : ]\n",
    "        return X, M, R, R_norm\n",
    "        \n",
    "\n",
    "#t = FactorDataset(stock_universe='TWSE', mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d20289aa-1d7f-46ba-aaa0-43721517041a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ è®€å–: Y:\\å› å­å›æ¸¬_æ±Ÿå»ºå½°\\å› å­åº«TWSE.pkl\n",
      "âš¡ å¿«å–ä½¿ç”¨: Y:\\å› å­å›æ¸¬_æ±Ÿå»ºå½°\\å› å­åº«TWSE.pkl\n",
      "âš¡ å¿«å–ä½¿ç”¨: Y:\\å› å­å›æ¸¬_æ±Ÿå»ºå½°\\å› å­åº«TWSE.pkl\n",
      "âš¡ å¿«å–ä½¿ç”¨: Y:\\å› å­å›æ¸¬_æ±Ÿå»ºå½°\\å› å­åº«TWSE.pkl\n",
      "âš¡ å¿«å–ä½¿ç”¨: Y:\\å› å­å›æ¸¬_æ±Ÿå»ºå½°\\å› å­åº«TWSE.pkl\n",
      "âš¡ å¿«å–ä½¿ç”¨: Y:\\å› å­å›æ¸¬_æ±Ÿå»ºå½°\\å› å­åº«TWSE.pkl\n",
      "âš¡ å¿«å–ä½¿ç”¨: Y:\\å› å­å›æ¸¬_æ±Ÿå»ºå½°\\å› å­åº«TWSE.pkl\n",
      "âš¡ å¿«å–ä½¿ç”¨: Y:\\å› å­å›æ¸¬_æ±Ÿå»ºå½°\\å› å­åº«TWSE.pkl\n",
      "âš¡ å¿«å–ä½¿ç”¨: Y:\\å› å­å›æ¸¬_æ±Ÿå»ºå½°\\å› å­åº«TWSE.pkl\n"
     ]
    }
   ],
   "source": [
    "#batch_size = 16 # æœ€åŸå§‹\n",
    "batch_size = 16\n",
    "\n",
    "train_set = FactorDataset(stock_universe='TWSE', mode='train')\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "valid_set = FactorDataset(stock_universe='TWSE', mode='valid')\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_set = FactorDataset(stock_universe='TWSE', mode='test')\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e85c29cd-1ee2-413e-b44e-e435e2c8d56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([976, 887])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.tensor_return.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc77d9c9-4408-435d-bf33-25cfb740cf6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([976, 887])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.tensor_return_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15003a2c-5cea-47f8-98e6-e0d95c6d29ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc450005-6a76-4791-9954-147acd719ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1e8a386-3d84-4346-abe7-2b7e4bd0679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from flash_attn import flash_attn_func\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MarketGuidedGating(nn.Module):\n",
    "    def __init__(self, market_dim, feature_dim, beta=5):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(market_dim, feature_dim)\n",
    "        nn.init.xavier_uniform_(self.fc.weight)  # åŠ é€™è¡Œ\n",
    "        nn.init.zeros_(self.fc.bias)             # åˆå§‹åŒ– bias ç‚º 0\n",
    "        self.beta = beta\n",
    "        self.feature_dim = feature_dim\n",
    "\n",
    "    def forward(self, x, m):\n",
    "        alpha = self.feature_dim * F.softmax(self.fc(m) / self.beta, dim=-1)\n",
    "        #print(\"fc weight max:\", self.fc.weight.max().item(), \"min:\", self.fc.weight.min().item())\n",
    "        #print(self.fc(m))\n",
    "        #print(m.max(), m.min())\n",
    "        #print(torch.isnan(m.any()))\n",
    "        #print(torch.isnan(self.fc(m)).any())\n",
    "        \n",
    "        #print(F.softmax(self.fc(m) / self.beta, dim=-1).sum(axis=1))\n",
    "        #print(alpha.shape)\n",
    "        #print(f'alpha : {alpha}')\n",
    "        \n",
    "        return x * alpha  # Hadamard product\n",
    "\n",
    "class IntraStockEncoder(nn.Module):\n",
    "    def __init__(self, feature_dim, embed_dim=256, nhead=4, max_len=60):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(feature_dim, embed_dim)#\n",
    "        self.register_buffer('pos_encoder', self._get_sinusoid_encoding_table(max_len, embed_dim))#\n",
    "        self.encoder_norm = nn.LayerNorm(embed_dim)#\n",
    "        \n",
    "        self.embed_dim = embed_dim#\n",
    "        self.nhead = nhead#\n",
    "        self.head_dim = embed_dim // nhead#\n",
    "        assert self.head_dim * nhead == embed_dim, \"embed_dim must be divisible by nhead\"#\n",
    "        \n",
    "        \n",
    "        self.qkv_proj = nn.Linear(embed_dim, 3 * embed_dim) #\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 4 * embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * embed_dim, embed_dim),\n",
    "        )\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, time, _ = x.shape#\n",
    "        x = self.input_proj(x)#\n",
    "        #print(f'x.shape : {x.shape}')\n",
    "        x = x + self.pos_encoder[:time, :].unsqueeze(0)#\n",
    "        x = self.encoder_norm(x)#\n",
    "\n",
    "        # QKV projection\n",
    "        qkv = self.qkv_proj(x)  # (batch, time, 3*embed_dim) #\n",
    "        qkv = qkv.view(batch, time, 3, self.nhead, self.head_dim) #\n",
    "        q, k, v = qkv.unbind(dim=2)  # (batch, time, nhead, head_dim) #\n",
    "\n",
    "        # Flash Attention\n",
    "        attn_out = flash_attn_func(q, k, v, dropout_p=0.0, causal=False)  # (batch, time, nhead, head_dim)#\n",
    "        attn_out = attn_out.view(batch, time, self.embed_dim)\n",
    "\n",
    "        # Residual + Norm\n",
    "        x = self.norm1(attn_out + x)\n",
    "\n",
    "        # Feed Forward\n",
    "        ffn_out = self.ffn(x)\n",
    "        out = self.norm2(ffn_out + x)  # æ³¨æ„é€™è£¡æ˜¯å†æ¬¡ residual+norm\n",
    "\n",
    "        return out\n",
    "\n",
    "    def _get_sinusoid_encoding_table(self, seq_len, d_model):\n",
    "        position = torch.arange(seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(seq_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return pe\n",
    "\n",
    "class InterStockAggregator(nn.Module):\n",
    "    def __init__(self, embed_dim=256, nhead=2):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.nhead = nhead\n",
    "        self.head_dim = embed_dim // nhead\n",
    "        assert self.head_dim * nhead == embed_dim, \"embed_dim must be divisible by nhead\"\n",
    "\n",
    "        self.qkv_proj = nn.Linear(embed_dim, 3 * embed_dim)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 4 * embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * embed_dim, embed_dim),\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, stocks, time, embed_dim = x.shape#\n",
    "\n",
    "        x_reshaped = x.permute(0, 2, 1, 3).reshape(batch * time, stocks, embed_dim)#\n",
    "\n",
    "        qkv = self.qkv_proj(x_reshaped)\n",
    "        qkv = qkv.view(batch * time, stocks, 3, self.nhead, self.head_dim)\n",
    "        q, k, v = qkv.unbind(dim=2)\n",
    "\n",
    "        attn_out = flash_attn_func(q, k, v, dropout_p=0.0, causal=False)\n",
    "        attn_out = attn_out.reshape(batch * time, stocks, embed_dim)\n",
    "\n",
    "        x_attn = self.norm1(attn_out + x_reshaped)\n",
    "        ffn_out = self.ffn(x_attn)\n",
    "        out = self.norm2(ffn_out + x_attn)\n",
    "\n",
    "        out = out.view(batch, time, stocks, embed_dim).permute(0, 2, 1, 3)\n",
    "\n",
    "        return out\n",
    "\n",
    "class TemporalAggregator(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.w_lambda = nn.Parameter(torch.randn(embed_dim, embed_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        query = x[:, :, -1, :]\n",
    "        scores = torch.einsum('bstf,fd,bsd->bst', x, self.w_lambda, query)\n",
    "        weights = F.softmax(scores, dim=2) \n",
    "        output = torch.einsum('bst,bstf->bsf', weights, x)\n",
    "        return output\n",
    "\n",
    "\n",
    "#def __init__(self, market_dim, feature_dim, embed_dim=256, nhead1=4, nhead2=2, beta=5):\n",
    "class MASTER(nn.Module):\n",
    "    def __init__(self, market_dim, feature_dim, embed_dim=256, nhead1=4, nhead2=2, beta=5):\n",
    "        super().__init__()\n",
    "        self.gating = MarketGuidedGating(market_dim, feature_dim, beta)\n",
    "        self.intra_encoder = IntraStockEncoder(feature_dim, embed_dim, nhead1)\n",
    "        self.inter_agg = InterStockAggregator(embed_dim, nhead2)\n",
    "        self.temporal_agg = TemporalAggregator(embed_dim)\n",
    "        self.predictor = nn.Linear(embed_dim, 1)\n",
    "\n",
    "    def forward(self, x, market):\n",
    "        batch, stocks, time, features = x.shape\n",
    "\n",
    "        market_expanded = market[:, None, None, :].expand(-1, stocks, time, -1)\n",
    "\n",
    "        #print(f'market_expanded : {torch.isnan(market_expanded).any()}')\n",
    "        market_scaled = self.gating(x, market_expanded)\n",
    "        \n",
    "        #print(f'market_scaled : {market_scaled}')\n",
    "        #if torch.isnan(market_scaled).any():\n",
    "        #    print(\"âš ï¸ market_scaled å« NaN\")\n",
    "\n",
    "        x_flat = market_scaled.view(batch * stocks, time, features)\n",
    "        local_embed = self.intra_encoder(x_flat)\n",
    "        \n",
    "        #print(f'intra_encoder : {local_embed}')\n",
    "        \n",
    "        local_embed = local_embed.view(batch, stocks, time, -1)\n",
    "\n",
    "        inter_embed = self.inter_agg(local_embed)\n",
    "        temporal_embed = self.temporal_agg(inter_embed)\n",
    "        out = self.predictor(temporal_embed).squeeze(-1)\n",
    "        #print(\"fc weight max:\", model.gating.fc.weight.max().item(), \"min:\", model.gating.fc.weight.min().item())\n",
    "        #print(f'torch.isnan(out).any() : {torch.isnan(out).any()}')\n",
    "        #print(f'out : {out}')\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc3fecf9-6e49-47db-ab3f-cf391635c5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#model = MASTER(market_dim=21, feature_dim=186, beta=2).to(device)\n",
    "\n",
    "model = MASTER(market_dim=21, feature_dim=186, embed_dim=256, nhead1=4, nhead2=2, beta=2).to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "#optimizer = optim.AdamW(model.parameters(), lr=0.5, weight_decay=1e-4)\n",
    "#optimizer = optim.AdamW(model.parameters(), lr=0.005, weight_decay=1e-4) \n",
    "criterion = nn.MSELoss() # OR LORENTIAN DIST\n",
    "#criterion = torch.nn.HuberLoss(delta=1.0)  # delta å¯èª¿æ•´ç‚º 0.5 ~ 2.0 è¦–èª¤å·®ç¯„åœ\n",
    "r_factor = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "57e3a1a3-1ea0-43f5-9814-cfa48cf236ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch 1 ===\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: predictor.weight\n",
      "âŒ Inf in gradient of: predictor.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "Train Loss: 1.5673\n",
      "Valid Loss: 1.5807\n",
      "âœ… Validation loss improved â€” model saved.\n",
      "ğŸ“‰ Current LR: 0.001\n",
      "=== Epoch 2 ===\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "Train Loss: 1.5674\n",
      "Valid Loss: 1.5807\n",
      "âš ï¸ No improvement. EarlyStopping counter: 1/20\n",
      "ğŸ“‰ Current LR: 0.001\n",
      "=== Epoch 3 ===\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ NaN in gradient of: gating.fc.weight\n",
      "âŒ NaN in gradient of: gating.fc.bias\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.input_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.weight\n",
      "âŒ NaN in gradient of: intra_encoder.encoder_norm.bias\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.weight\n",
      "âŒ NaN in gradient of: intra_encoder.qkv_proj.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.0.bias\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.ffn.2.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm1.bias\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.weight\n",
      "âŒ NaN in gradient of: intra_encoder.norm2.bias\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.weight\n",
      "âŒ NaN in gradient of: inter_agg.qkv_proj.bias\n",
      "âŒ Inf in gradient of: inter_agg.qkv_proj.bias\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 65\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m         param_norm \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnorm(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# L2 norm\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m         total_norm \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m param_norm\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;66;03m#print(param_norm)\u001b[39;00m\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;66;03m#print(f'torch.isnan(loss).any() : {torch.isnan(loss).any()}')\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_parameters():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir runs\n",
    "\n",
    "    \n",
    "scaler = GradScaler()\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.8,        # ä¸€æ¬¡ç åŠ\n",
    "    patience=3,        # èª¿å°ä¸€é»\n",
    "    threshold=5e-4,     \n",
    "    threshold_mode='abs',\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "epochs = 500\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "patience = 20           # å¯ä»¥å®¹å¿å¤šå°‘æ¬¡æ²’é€²æ­¥\n",
    "counter = 0             # æ²’é€²æ­¥çš„æ¬¡æ•¸\n",
    "min_delta = 1e-4        # å¦‚æœæ”¹å–„å°‘æ–¼é€™å€‹å€¼ï¼Œå°±ä¸ç®—é€²æ­¥\n",
    "\n",
    "# åˆå§‹åŒ– TensorBoard writer\n",
    "#writer = SummaryWriter(log_dir='runs/experiment_1')\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'=== Epoch {epoch + 1} ===')\n",
    "\n",
    "    # -------- Training Phase --------\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        factors, market, returns, returns_norm = batch\n",
    "        factors, market, returns_norm = factors.to(device), market.to(device), returns_norm.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast('cuda', dtype=torch.float16):\n",
    "            logits = model(factors, market)\n",
    "            #print(f'torch.isnan(logits).any() : {torch.isnan(logits).any()}')\n",
    "            \n",
    "            loss = criterion(logits, returns_norm*r_factor)\n",
    "            #print(f'torch.isnan(loss).any() : {torch.isnan(loss).any()}')\n",
    "            #print(f'loss : {loss}')\n",
    "\n",
    "        #print(\"Scaler scale:\", scaler.get_scale())\n",
    "\n",
    "        #for name, param in model.named_parameters():\n",
    "        #    if param.grad is not None and torch.isnan(param.grad).any():\n",
    "        #        print(f\"â— NaN in gradient of layer: {name}\")\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)  # è®“ clip_grad å’Œæª¢æŸ¥èƒ½çœ‹åˆ°çœŸå¯¦æ¢¯åº¦\n",
    "\n",
    "\n",
    "        total_norm = 0.0\n",
    "        for p in model.parameters():\n",
    "            if p.grad is not None:\n",
    "                param_norm = p.grad.data.norm(2)  # L2 norm\n",
    "                total_norm += param_norm.item() ** 2\n",
    "                #print(param_norm)\n",
    "                #print(f'torch.isnan(loss).any() : {torch.isnan(loss).any()}')\n",
    "\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                if torch.isnan(param.grad).any():\n",
    "                    print(f\"âŒ NaN in gradient of: {name}\")\n",
    "                if torch.isinf(param.grad).any():\n",
    "                    print(f\"âŒ Inf in gradient of: {name}\")\n",
    "\n",
    "        \n",
    "        total_norm = total_norm ** 0.5\n",
    "        #print(f\"ğŸ¯ Gradient Norm: {total_norm:.6f}\")\n",
    "\n",
    "\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item()     \n",
    "        \n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f'Train Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "    # -------- Validation Phase --------\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_loader:\n",
    "            factors, market, returns, returns_norm = batch\n",
    "            factors, market, returns_norm = factors.to(device), market.to(device), returns_norm.to(device)\n",
    "\n",
    "            with autocast('cuda', dtype=torch.float16):\n",
    "                logits = model(factors, market)\n",
    "                loss = criterion(logits, returns_norm*r_factor)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "    avg_valid_loss = valid_loss / len(valid_loader)\n",
    "    print(f'Valid Loss: {avg_valid_loss:.4f}')\n",
    "\n",
    "    \n",
    "    #writer.add_scalar('Loss/Train', avg_train_loss, epoch)\n",
    "    #writer.add_scalar('Loss/Valid', avg_valid_loss, epoch)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # -------- Early Stopping æª¢æŸ¥ --------\n",
    "    if avg_valid_loss + min_delta < best_valid_loss:\n",
    "        best_valid_loss = avg_valid_loss\n",
    "        counter = 0\n",
    "        print(\"âœ… Validation loss improved â€” model saved.\")\n",
    "        torch.save(model.state_dict(), \"MASTER_best_model_retrain.pt\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"âš ï¸ No improvement. EarlyStopping counter: {counter}/{patience}\")\n",
    "        if counter >= patience:\n",
    "            print(\"ğŸ›‘ Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    scheduler.step(avg_valid_loss)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(f\"ğŸ“‰ Current LR: {param_group['lr']}\")\n",
    "\n",
    "# -------- Close TensorBoard Writer --------\n",
    "#writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f90fcc-f4a9-4e8e-9eb6-c4ab97427296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaa8091-000e-4973-bed1-611e7d70a05f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c5ba42-562e-4fac-9477-21d07ffd41b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ed3df8-82e8-4cca-9cc2-3388c2a02175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f101fe5-4ee7-4495-90d3-b30121fa7e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43bcbf3a-f513-4f26-8720-22f1db28f8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.0304\n"
     ]
    }
   ],
   "source": [
    "model = MASTER(market_dim=21, feature_dim=186, embed_dim=256, nhead1=4, nhead2=2, beta=2).to(device)\n",
    "state_dict = torch.load(\"MASTER_best_model.pt\", weights_only=True)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model.eval()  # è¨­å®šç‚ºè©•ä¼°æ¨¡å¼ï¼ˆé—œé–‰ dropoutã€batchnormï¼‰\n",
    "\n",
    "test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        factors, market, returns, returns_norm = batch\n",
    "        #print(factors.shape, market.shape)\n",
    "        #break\n",
    "        factors, market, returns, returns_norm = factors.to(device), market.to(device), returns.to(device), returns_norm.to(device)\n",
    "\n",
    "        with autocast('cuda', dtype=torch.float16):\n",
    "            logits = model(factors, market)\n",
    "            loss = criterion(logits, returns_norm*r_factor)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "print(f'Test Loss: {avg_test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653d7a72-480c-4c76-9217-59f64d5868da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3dd7b12-959d-4d0e-9fbe-eb4b7da7f441",
   "metadata": {},
   "source": [
    "# é©—è­‰æ¨¡å‹å¥½å£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "848ee821-568b-405c-a34c-6053216ddea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MASTER(market_dim=21, feature_dim=186, embed_dim=256, nhead1=4, nhead2=2, beta=2).to(device)\n",
    "state_dict = torch.load(\"MASTER_best_model.pt\", weights_only=True)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model.eval()  # è¨­å®šç‚ºè©•ä¼°æ¨¡å¼ï¼ˆé—œé–‰ dropoutã€batchnormï¼‰\n",
    "\n",
    "factors, market, returns = test_set.tensor_factor, test_set.tensor_market, test_set.tensor_return\n",
    "factors, market = factors.to(device), market.to(device)\n",
    "\n",
    "lookback = 8\n",
    "valid_length = len(market) - lookback\n",
    "\n",
    "cum = 1\n",
    "cum_list = []\n",
    "with torch.no_grad():\n",
    "    for idx in range(valid_length):\n",
    "        X = factors[ : , idx:idx+lookback, : ] # (stock, time, factor)\n",
    "        M = market[idx+lookback-1, : ]\n",
    "\n",
    "        X = X.unsqueeze(0) # (batch=1, stock, time, factor)\n",
    "        M = M.unsqueeze(0) # (batch=1, feature)\n",
    "        ret = returns[idx+lookback-1, : ]\n",
    "        #print(X.shape, M.shape, ret.shape)\n",
    "        \n",
    "        \n",
    "        with autocast('cuda', dtype=torch.float16):\n",
    "            logits = model(X, M)\n",
    "            logits = logits.squeeze()\n",
    "            logits = logits.cpu()\n",
    "            #print(logits.shape)\n",
    "        top_indices = torch.topk(logits, 30, largest=True).indices\n",
    "        bottom_indices = torch.topk(logits, 30, largest=False).indices\n",
    "\n",
    "        final_ret = (torch.mean(ret[top_indices])-torch.mean(ret[bottom_indices]))/2\n",
    "        \n",
    "        cum = cum*(1+final_ret)\n",
    "        cum_list.append(cum)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8f6dbd3-362a-4598-bab7-cc77b3452e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b9a873a870>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(cum_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df34d0-0a39-45dc-8234-125cefb1bc17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c5e4f7-6a07-4aa1-8099-4c9a320e45ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
